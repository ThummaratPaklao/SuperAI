{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69de51ab751a4cc9a94ee6e14579c7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0dfe5bca70644cdfa364bc6e9591a87e",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_899664fdc09e4d50b89e6ef79a842e59"
          }
        },
        "0dfe5bca70644cdfa364bc6e9591a87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "899664fdc09e4d50b89e6ef79a842e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a1bb85ffb6f411e9b4e47b1ae13e793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_d83c22aa72d74c4db10ef506f47ea46a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66825b4620354386b816592f935bbbbd"
          }
        },
        "d83c22aa72d74c4db10ef506f47ea46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66825b4620354386b816592f935bbbbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bafed17c4fd4f65b09aa952ce4be872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe3497849a2a4445a67385b85981ce0f",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 74,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 74,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df801dbb519d4864912d5cfc0ffd67a9"
          }
        },
        "fe3497849a2a4445a67385b85981ce0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df801dbb519d4864912d5cfc0ffd67a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfb910b0aced48b4beac1dcfb8678a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7631a6bf2ba44efabb5fa82f530a9d7a",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c6263428bd240278b4b47cf1baea28c"
          }
        },
        "7631a6bf2ba44efabb5fa82f530a9d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c6263428bd240278b4b47cf1baea28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf8da32ca37e42b88131b58f72c88e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_19b9039175b74c95b5b8289d8c45ec40",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5da375e3867249768662a387e3ba6665"
          }
        },
        "19b9039175b74c95b5b8289d8c45ec40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5da375e3867249768662a387e3ba6665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1b0a34673d2418f86b93b35b52a423d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16b80db8ea774676a4ce0efa3458a0fe",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a3e884ca0684e7a88cc910a306f6321"
          }
        },
        "16b80db8ea774676a4ce0efa3458a0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a3e884ca0684e7a88cc910a306f6321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d3049ceb63c491eab22ee96087677aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c4d61fef7fc4260a9ca19af90188bec",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 74,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 74,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d88d127398f446e87336a29df3cf6af"
          }
        },
        "5c4d61fef7fc4260a9ca19af90188bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d88d127398f446e87336a29df3cf6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96bab5a1fec142cabd2e9742c6c38871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a855cd761a840eb9fcfab32cd788875",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 74,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 74,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_558aa041d7964170992a6467cb411f64"
          }
        },
        "6a855cd761a840eb9fcfab32cd788875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "558aa041d7964170992a6467cb411f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ba2d65f73974962a44b001d1abce035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01bdfbd6f9a642a38c1417b6f1e78fb9",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 74,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 74,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2d739ae4f9b4bea8e3bf957e24acf12"
          }
        },
        "01bdfbd6f9a642a38c1417b6f1e78fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2d739ae4f9b4bea8e3bf957e24acf12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2e64910dcce4e47b90d72f407f87148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e7b0e48f64c4d45ae5c6666e5d2fa77",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 74,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 74,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4008127b40c84eaca60a061bc0cb9db0"
          }
        },
        "0e7b0e48f64c4d45ae5c6666e5d2fa77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4008127b40c84eaca60a061bc0cb9db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15b26ebcc41f4e5c9dd51964e73d03a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fca724191624095a8995664f9ff4084",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 74,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 74,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3de5afc889746ddb635ba7b7c481b12"
          }
        },
        "4fca724191624095a8995664f9ff4084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3de5afc889746ddb635ba7b7c481b12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy  as np\n",
        "import pandas as pd\n",
        "from   tqdm   import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn\")\n",
        "from IPython.display import clear_output\n",
        "from scipy.signal import argrelextrema\n",
        "import ast\n",
        "\n",
        "import time\n",
        "from datetime import datetime,date"
      ],
      "metadata": {
        "id": "4MvGgqO_OIas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Deepinvest-team/deepinvest_open_environment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_p9CCy7d0LU",
        "outputId": "eb0489ba-807d-48d5-bce7-f060b75f35a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepinvest_open_environment'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/deepinvest_open_environment')\n",
        "from deepinvest_open_environment.Observer import Observers"
      ],
      "metadata": {
        "id": "T-6lAb0yif5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Trainset"
      ],
      "metadata": {
        "id": "NizNBIUiPxcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Testset"
      ],
      "metadata": {
        "id": "Q3n11d5kP6Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#asset01-train\n",
        "!gdown --id 1mXz42aGzAQcPCaeDInxsojHkPLcvymOA\n",
        "#asset02-train\n",
        "!gdown --id 1JJCS_SicAqo-fmIVfLpMUhk5KLmpKWFt\n",
        "#asset03-train\n",
        "!gdown --id 1W1FcZSOwkJEhmo4Oi5XQqXkWbILrj7H2\n",
        "#asset04-train\n",
        "!gdown --id 1aWPsgj6IcpiOdwws7XOz6M0zIou1zm7D\n",
        "#asset05-train\n",
        "!gdown --id 17H6To6RVq9KXt54hgMEN7tWX5fd87tuz\n",
        "#asset01-test\n",
        "!gdown --id 1lM419SCZhFCGej_onEikgU5M3s9B9mId\n",
        "#asset02-test\n",
        "!gdown --id 1jLL_N80Ciit-GQ5NAUm-bGwFl23ZhWVS\n",
        "#asset03-test\n",
        "!gdown --id 1YL70mrBQSoqFcHBniAcc9ZOGYudrH0xr\n",
        "#asset04-test\n",
        "!gdown --id 1DnqGz1GjlHWwFDRPksab_ig-o1C67ZDm\n",
        "#asset05-test\n",
        "!gdown --id 1WCNAXTeiSMRgoOGFSk0UfBtIjXUbNDx_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYs-HI3QP5vG",
        "outputId": "9fa4a4d7-8077-401a-a219-521a02306785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mXz42aGzAQcPCaeDInxsojHkPLcvymOA\n",
            "To: /content/Asset01_train.csv\n",
            "100% 195k/195k [00:00<00:00, 55.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JJCS_SicAqo-fmIVfLpMUhk5KLmpKWFt\n",
            "To: /content/Asset02_train.csv\n",
            "100% 191k/191k [00:00<00:00, 54.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1W1FcZSOwkJEhmo4Oi5XQqXkWbILrj7H2\n",
            "To: /content/Asset03_train.csv\n",
            "100% 190k/190k [00:00<00:00, 60.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aWPsgj6IcpiOdwws7XOz6M0zIou1zm7D\n",
            "To: /content/Asset04_train.csv\n",
            "100% 199k/199k [00:00<00:00, 43.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17H6To6RVq9KXt54hgMEN7tWX5fd87tuz\n",
            "To: /content/Asset05_train.csv\n",
            "100% 195k/195k [00:00<00:00, 62.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lM419SCZhFCGej_onEikgU5M3s9B9mId\n",
            "To: /content/Asset01_test.csv\n",
            "100% 21.6k/21.6k [00:00<00:00, 20.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jLL_N80Ciit-GQ5NAUm-bGwFl23ZhWVS\n",
            "To: /content/Asset02_test.csv\n",
            "100% 21.3k/21.3k [00:00<00:00, 20.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YL70mrBQSoqFcHBniAcc9ZOGYudrH0xr\n",
            "To: /content/Asset03_test.csv\n",
            "100% 21.0k/21.0k [00:00<00:00, 29.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DnqGz1GjlHWwFDRPksab_ig-o1C67ZDm\n",
            "To: /content/Asset04_test.csv\n",
            "100% 21.5k/21.5k [00:00<00:00, 25.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WCNAXTeiSMRgoOGFSk0UfBtIjXUbNDx_\n",
            "To: /content/Asset05_test.csv\n",
            "100% 21.8k/21.8k [00:00<00:00, 30.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import lib"
      ],
      "metadata": {
        "id": "7-N0RpHgid1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JSoIGukmqL_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง environment\n",
        " * Observers(windowsize,train=True)\n",
        " * Observers จะเป็นสภาพแวดล้อมที่ใช้ในการทดสอบโมเดล โดย parameter จะประกอบไปด้วย window size ซึ่งเป็นขนาดของข้อมูลย้อนหลังที่ต้องการเห็น และ train จะเป็นค่า True หรือ False ซึ่งเป็นค่าที่ใช้เปลี่ยนข้อมูลของ environment โดย train ระบบจะดึงข้อมูลชุด train มาให้ ส่วน test ระบบจะดึงข้อมูลส่วน test มาให้\n",
        ""
      ],
      "metadata": {
        "id": "3sOOAFFSY_cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#observers = Observers(30,train=False)\n",
        "observers = Observers(30,train=True)"
      ],
      "metadata": {
        "id": "Il4JLmQZY_Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**getCodeAsset**\n",
        "  * getCodeAsset บอกรหัสของ Asset ที่ใช้ในการเปิดคำสั่งซื้อขาย"
      ],
      "metadata": {
        "id": "joN5mZIiepKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**getDataset**\n",
        "  * getDataset เรียกข้อมูลย้อนหลังทั้งหมด"
      ],
      "metadata": {
        "id": "bgY3hpJMfAtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader as web\n",
        "\n",
        "def calculate_ema(prices, days, smoothing=2):\n",
        "    ema = [sum(prices[:days]) / days]\n",
        "    for price in prices[days:]:\n",
        "        ema.append((price * (smoothing / (1 + days))) + ema[-1] * (1 - (smoothing / (1 + days))))\n",
        "    return ema"
      ],
      "metadata": {
        "id": "e-fxfM1TWvPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(observers.getDataset()['Asset01']['close'])\n",
        "print(total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqstzHKWOJDG",
        "outputId": "f6983d52-1e66-43de-cef1-3849da089f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install talib-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKI6AnEzhz9t",
        "outputId": "d8417444-a9de-4c19-967a-d4f860ec70e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting talib-binary\n",
            "  Downloading talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from talib-binary) (1.21.5)\n",
            "Installing collected packages: talib-binary\n",
            "Successfully installed talib-binary-0.4.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import talib\n",
        "# CDC ActionZone V.2\n",
        "def CDCActionZoneV2(close, fast, slow):\n",
        "  AP = talib.EMA(close,2)\n",
        "  fast = talib.EMA(AP,fast)\n",
        "  slow = talib.EMA(AP,slow)\n",
        "\n",
        "  signal = fast - slow\n",
        "\n",
        "  return signal, fast, slow"
      ],
      "metadata": {
        "id": "MBlFWMe2h1Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addFeature(asset):\n",
        "  feature = {}\n",
        "  ema12 = calculate_ema(observers.getDataset()[asset]['close'], 12)\n",
        "  ema26 = calculate_ema(observers.getDataset()[asset]['close'], 26)\n",
        "  cdc, f, s = CDCActionZoneV2(observers.getDataset()[asset]['close'], 12, 26)\n",
        "  macd, macdsignal, macdhist = talib.MACD(observers.getDataset()[asset]['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "  adx = talib.ADX(observers.getDataset()[asset]['high'], observers.getDataset()[asset]['low'], observers.getDataset()[asset]['close'], timeperiod=14) # unstable period.\n",
        "  roc = talib.ROC(observers.getDataset()[asset]['close'], timeperiod=5)\n",
        "  rsi = talib.RSI(observers.getDataset()[asset]['close'], timeperiod=14)\n",
        "  stoch, slowd = talib.STOCH(observers.getDataset()[asset]['high'], observers.getDataset()[asset]['low'], observers.getDataset()[asset]['close'], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
        "\n",
        "  for i in range(total-len(ema12)):\n",
        "    ema12.insert(0,0)\n",
        "  for i in range(total-len(ema26)):\n",
        "    ema26.insert(0,0)\n",
        "  for i in range(total-len(cdc)):\n",
        "    cdc.insert(0,0)\n",
        "  for i in range(total-len(macd)):\n",
        "    macd.insert(0,0)\n",
        "  for i in range(total-len(adx)):\n",
        "    adx.insert(0,0)\n",
        "  for i in range(total-len(roc)):\n",
        "    roc.insert(0,0)\n",
        "  for i in range(total-len(rsi)):\n",
        "    rsi.insert(0,0)\n",
        "  for i in range(total-len(stoch)):\n",
        "    stoch.insert(0,0)\n",
        "\n",
        "  feature = {\n",
        "      'EMA12' : ema12,\n",
        "      'EMA26' : ema26,\n",
        "      'CDC' : cdc,\n",
        "      'MACD' : macd,\n",
        "      'ADX' : adx,\n",
        "      'ROC' : roc,\n",
        "      'RSI' : rsi,\n",
        "      'STOCH' : stoch\n",
        "\n",
        "\n",
        "  }\n",
        "\n",
        "  observers.getDataset()[asset]['EMA12'] = feature['EMA12']\n",
        "  observers.getDataset()[asset]['EMA26'] = feature['EMA26']\n",
        "  observers.getDataset()[asset]['CDC'] = feature['CDC']\n",
        "  observers.getDataset()[asset]['MACD'] = feature['MACD']\n",
        "  observers.getDataset()[asset]['ADX'] = feature['ADX']\n",
        "  observers.getDataset()[asset]['ROC'] = feature['ROC']\n",
        "  observers.getDataset()[asset]['RSI'] = feature['RSI']\n",
        "  observers.getDataset()[asset]['STOCH'] = feature['STOCH']\n",
        "  return feature"
      ],
      "metadata": {
        "id": "XDbN2ONLVc_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FA01 = addFeature('Asset01')\n",
        "FA02 = addFeature('Asset02')\n",
        "FA03 = addFeature('Asset03')\n",
        "FA04 = addFeature('Asset04')\n",
        "FA05 = addFeature('Asset05')"
      ],
      "metadata": {
        "id": "AXGDGB7HV_yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'Day': []})\n",
        "df2 = pd.DataFrame({'Day': []})\n",
        "df3 = pd.DataFrame({'Day': []})\n",
        "df4 = pd.DataFrame({'Day': []})\n",
        "df5 = pd.DataFrame({'Day': []})"
      ],
      "metadata": {
        "id": "6KAC6q62ZwLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Day'] = observers.getDataset()['Asset01'].index\n",
        "df2['Day'] = observers.getDataset()['Asset02'].index\n",
        "df3['Day'] = observers.getDataset()['Asset03'].index\n",
        "df4['Day'] = observers.getDataset()['Asset04'].index\n",
        "df5['Day'] = observers.getDataset()['Asset05'].index"
      ],
      "metadata": {
        "id": "EoRzxWgTZ0F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-cieXvKAZ4Qg",
        "outputId": "d1fd94b8-2913-48ae-9594-ec6885e9a629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b6fc3581-9ffd-4678-b6c8-3dc5deb86018\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>2018-12-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>2018-12-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>2018-12-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2109</th>\n",
              "      <td>2018-12-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>2018-12-28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2111 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6fc3581-9ffd-4678-b6c8-3dc5deb86018')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6fc3581-9ffd-4678-b6c8-3dc5deb86018 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6fc3581-9ffd-4678-b6c8-3dc5deb86018');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             Day\n",
              "0     2010-01-04\n",
              "1     2010-01-05\n",
              "2     2010-01-06\n",
              "3     2010-01-07\n",
              "4     2010-01-08\n",
              "...          ...\n",
              "2106  2018-12-21\n",
              "2107  2018-12-24\n",
              "2108  2018-12-26\n",
              "2109  2018-12-27\n",
              "2110  2018-12-28\n",
              "\n",
              "[2111 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getDataset()['Asset01'].reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pdk9iFDqcyUJ",
        "outputId": "4a3ef40e-0256-44df-daf2-bacbbef242c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-082e378b-4e94-4b5d-bed6-9ec78df22c47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>EMA12</th>\n",
              "      <th>EMA26</th>\n",
              "      <th>CDC</th>\n",
              "      <th>MACD</th>\n",
              "      <th>ADX</th>\n",
              "      <th>ROC</th>\n",
              "      <th>RSI</th>\n",
              "      <th>STOCH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.854970</td>\n",
              "      <td>13.979149</td>\n",
              "      <td>13.788238</td>\n",
              "      <td>13.937369</td>\n",
              "      <td>45505</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.936982</td>\n",
              "      <td>14.006905</td>\n",
              "      <td>13.875086</td>\n",
              "      <td>13.890270</td>\n",
              "      <td>46686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.891043</td>\n",
              "      <td>13.959323</td>\n",
              "      <td>13.813577</td>\n",
              "      <td>13.926440</td>\n",
              "      <td>45435</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.926730</td>\n",
              "      <td>13.970735</td>\n",
              "      <td>13.829341</td>\n",
              "      <td>13.833886</td>\n",
              "      <td>44298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.833693</td>\n",
              "      <td>13.952069</td>\n",
              "      <td>13.794524</td>\n",
              "      <td>13.934854</td>\n",
              "      <td>34425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>11.069063</td>\n",
              "      <td>11.096432</td>\n",
              "      <td>10.982311</td>\n",
              "      <td>10.992853</td>\n",
              "      <td>93835</td>\n",
              "      <td>10.993945</td>\n",
              "      <td>10.996392</td>\n",
              "      <td>-0.003483</td>\n",
              "      <td>-0.002447</td>\n",
              "      <td>11.335020</td>\n",
              "      <td>0.541339</td>\n",
              "      <td>49.568812</td>\n",
              "      <td>60.527210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>10.993820</td>\n",
              "      <td>11.062099</td>\n",
              "      <td>10.986470</td>\n",
              "      <td>11.041113</td>\n",
              "      <td>64548</td>\n",
              "      <td>11.001202</td>\n",
              "      <td>10.999705</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.001497</td>\n",
              "      <td>11.315980</td>\n",
              "      <td>0.610729</td>\n",
              "      <td>53.817202</td>\n",
              "      <td>57.446659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>11.039178</td>\n",
              "      <td>11.039468</td>\n",
              "      <td>10.969352</td>\n",
              "      <td>10.978830</td>\n",
              "      <td>41184</td>\n",
              "      <td>10.997760</td>\n",
              "      <td>10.998158</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000399</td>\n",
              "      <td>10.904662</td>\n",
              "      <td>-0.070423</td>\n",
              "      <td>48.176532</td>\n",
              "      <td>32.609183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2109</th>\n",
              "      <td>10.980377</td>\n",
              "      <td>11.077283</td>\n",
              "      <td>10.978056</td>\n",
              "      <td>11.053492</td>\n",
              "      <td>99672</td>\n",
              "      <td>11.006334</td>\n",
              "      <td>11.002257</td>\n",
              "      <td>0.002611</td>\n",
              "      <td>0.004077</td>\n",
              "      <td>11.234929</td>\n",
              "      <td>0.467651</td>\n",
              "      <td>54.352972</td>\n",
              "      <td>40.412307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>11.055136</td>\n",
              "      <td>11.095175</td>\n",
              "      <td>11.050397</td>\n",
              "      <td>11.063743</td>\n",
              "      <td>82072</td>\n",
              "      <td>11.015166</td>\n",
              "      <td>11.006812</td>\n",
              "      <td>0.006440</td>\n",
              "      <td>0.008354</td>\n",
              "      <td>11.849621</td>\n",
              "      <td>-0.047181</td>\n",
              "      <td>55.143488</td>\n",
              "      <td>47.275870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2111 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-082e378b-4e94-4b5d-bed6-9ec78df22c47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-082e378b-4e94-4b5d-bed6-9ec78df22c47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-082e378b-4e94-4b5d-bed6-9ec78df22c47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           open       high        low  ...       ROC        RSI      STOCH\n",
              "0     13.854970  13.979149  13.788238  ...       NaN        NaN        NaN\n",
              "1     13.936982  14.006905  13.875086  ...       NaN        NaN        NaN\n",
              "2     13.891043  13.959323  13.813577  ...       NaN        NaN        NaN\n",
              "3     13.926730  13.970735  13.829341  ...       NaN        NaN        NaN\n",
              "4     13.833693  13.952069  13.794524  ...       NaN        NaN        NaN\n",
              "...         ...        ...        ...  ...       ...        ...        ...\n",
              "2106  11.069063  11.096432  10.982311  ...  0.541339  49.568812  60.527210\n",
              "2107  10.993820  11.062099  10.986470  ...  0.610729  53.817202  57.446659\n",
              "2108  11.039178  11.039468  10.969352  ... -0.070423  48.176532  32.609183\n",
              "2109  10.980377  11.077283  10.978056  ...  0.467651  54.352972  40.412307\n",
              "2110  11.055136  11.095175  11.050397  ... -0.047181  55.143488  47.275870\n",
              "\n",
              "[2111 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def addFeat(df, asset):\n",
        "  df['Close'] = observers.getDataset()[asset]['close'].reset_index(drop=True)\n",
        "  df['CDC'] = observers.getDataset()[asset]['CDC'].reset_index(drop=True)\n",
        "  df['MACD'] = observers.getDataset()[asset]['MACD'].reset_index(drop=True)\n",
        "  df['ADX'] = observers.getDataset()[asset]['ADX'].reset_index(drop=True)\n",
        "  df['ROC'] = observers.getDataset()[asset]['ROC'].reset_index(drop=True)\n",
        "  df['RSI'] = observers.getDataset()[asset]['RSI'].reset_index(drop=True)\n",
        "  df['STOCH'] = observers.getDataset()[asset]['STOCH'].reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "wDoWP1oobKT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc1 = addFeat(df, 'Asset01')\n",
        "acc2 = addFeat(df2, 'Asset02')\n",
        "acc3 = addFeat(df3, 'Asset03')\n",
        "acc4 = addFeat(df4, 'Asset04')\n",
        "acc5 = addFeat(df5, 'Asset05')"
      ],
      "metadata": {
        "id": "65PupHlDaGwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REAL ACTION PROFIT\n",
        "def getCDCRealPosition(newDf):\n",
        "  dayLong = []\n",
        "  Long = []\n",
        "  dayCount = []\n",
        "  day = 0\n",
        "  buy = 0\n",
        "  sell = 0\n",
        "  for i in range(len(newDf['Day'])):\n",
        "    if newDf['CDC'][i] > 0:\n",
        "      if buy == 0:\n",
        "        dayLong.append(newDf['Day'][i])\n",
        "        Long.append(1)\n",
        "        buy = newDf['Close'][i]\n",
        "      day += 1\n",
        "    else:\n",
        "      if buy != 0:\n",
        "        sell = newDf['Close'][i]\n",
        "        if buy > sell:\n",
        "          dayLong.pop()\n",
        "          Long.pop()\n",
        "          day = 0\n",
        "        else:\n",
        "          dayCount.append(day)\n",
        "          day = 0\n",
        "      sell = 0\n",
        "      buy = 0\n",
        "\n",
        "  if day != 0:\n",
        "    dayCount.append(day)\n",
        "\n",
        "  return pd.DataFrame({'Day': dayLong, 'Long':Long}), dayCount"
      ],
      "metadata": {
        "id": "4utABwv3dUhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cdcReal01, Day01 = getCDCRealPosition(acc1)\n",
        "cdcReal02, Day02 = getCDCRealPosition(acc2)\n",
        "cdcReal03, Day03 = getCDCRealPosition(acc3)\n",
        "cdcReal04, Day04 = getCDCRealPosition(acc4)\n",
        "cdcReal05, Day05 = getCDCRealPosition(acc5)"
      ],
      "metadata": {
        "id": "L3Z0rH1Tdhf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Day01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS8pKtJBwsNe",
        "outputId": "c0f74852-6faa-4461-b635-cfb57335cfd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cdcReal01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "oR_QZn9Cejsz",
        "outputId": "daf8d147-6a01-462f-94b2-9f117eca44a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d460ee86-9d47-4062-92f4-89d09b76e4e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Day</th>\n",
              "      <th>Long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-07-07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-09-15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-08-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-11-27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2013-09-16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2013-11-29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2014-02-14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-01-28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-03-07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2017-04-20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2017-11-22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2018-12-27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d460ee86-9d47-4062-92f4-89d09b76e4e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d460ee86-9d47-4062-92f4-89d09b76e4e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d460ee86-9d47-4062-92f4-89d09b76e4e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Day  Long\n",
              "0   2010-07-07     1\n",
              "1   2010-09-15     1\n",
              "2   2011-01-20     1\n",
              "3   2012-08-21     1\n",
              "4   2012-11-27     1\n",
              "5   2013-09-16     1\n",
              "6   2013-11-29     1\n",
              "7   2014-02-14     1\n",
              "8   2016-01-28     1\n",
              "9   2016-03-07     1\n",
              "10  2017-04-20     1\n",
              "11  2017-11-22     1\n",
              "12  2018-12-27     1"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result01 = pd.merge(acc1, cdcReal01, how=\"outer\", on=['Day'])\n",
        "result01 = result01.fillna(0)\n",
        "result01 = result01.drop({'Day','Close'}, axis=1)\n",
        "\n",
        "result02 = pd.merge(acc2, cdcReal02, how=\"outer\", on=['Day'])\n",
        "result02 = result02.fillna(0)\n",
        "result02 = result02.drop({'Day','Close'}, axis=1)\n",
        "\n",
        "result03 = pd.merge(acc3, cdcReal03, how=\"outer\", on=['Day'])\n",
        "result03 = result03.fillna(0)\n",
        "result03 = result03.drop({'Day','Close'}, axis=1)\n",
        "\n",
        "result04 = pd.merge(acc4, cdcReal04, how=\"outer\", on=['Day'])\n",
        "result04 = result04.fillna(0)\n",
        "result04 = result04.drop({'Day','Close'}, axis=1)\n",
        "\n",
        "result05 = pd.merge(acc5, cdcReal05, how=\"outer\", on=['Day'])\n",
        "result05 = result05.fillna(0)\n",
        "result05 = result05.drop({'Day','Close'}, axis=1)"
      ],
      "metadata": {
        "id": "8uehaxZKe0mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2f7JFOGZk-eZ",
        "outputId": "047f3598-15cd-49f1-c3ff-7725db241393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2b65e31a-b7a4-41f9-8d5c-63da2fcc73e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CDC</th>\n",
              "      <th>MACD</th>\n",
              "      <th>ADX</th>\n",
              "      <th>ROC</th>\n",
              "      <th>RSI</th>\n",
              "      <th>STOCH</th>\n",
              "      <th>Long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>-0.003483</td>\n",
              "      <td>-0.002447</td>\n",
              "      <td>11.335020</td>\n",
              "      <td>0.541339</td>\n",
              "      <td>49.568812</td>\n",
              "      <td>60.527210</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.001497</td>\n",
              "      <td>11.315980</td>\n",
              "      <td>0.610729</td>\n",
              "      <td>53.817202</td>\n",
              "      <td>57.446659</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.000399</td>\n",
              "      <td>10.904662</td>\n",
              "      <td>-0.070423</td>\n",
              "      <td>48.176532</td>\n",
              "      <td>32.609183</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2109</th>\n",
              "      <td>0.002611</td>\n",
              "      <td>0.004077</td>\n",
              "      <td>11.234929</td>\n",
              "      <td>0.467651</td>\n",
              "      <td>54.352972</td>\n",
              "      <td>40.412307</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>0.006440</td>\n",
              "      <td>0.008354</td>\n",
              "      <td>11.849621</td>\n",
              "      <td>-0.047181</td>\n",
              "      <td>55.143488</td>\n",
              "      <td>47.275870</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2111 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b65e31a-b7a4-41f9-8d5c-63da2fcc73e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b65e31a-b7a4-41f9-8d5c-63da2fcc73e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b65e31a-b7a4-41f9-8d5c-63da2fcc73e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           CDC      MACD        ADX       ROC        RSI      STOCH  Long\n",
              "0     0.000000  0.000000   0.000000  0.000000   0.000000   0.000000   0.0\n",
              "1     0.000000  0.000000   0.000000  0.000000   0.000000   0.000000   0.0\n",
              "2     0.000000  0.000000   0.000000  0.000000   0.000000   0.000000   0.0\n",
              "3     0.000000  0.000000   0.000000  0.000000   0.000000   0.000000   0.0\n",
              "4     0.000000  0.000000   0.000000  0.000000   0.000000   0.000000   0.0\n",
              "...        ...       ...        ...       ...        ...        ...   ...\n",
              "2106 -0.003483 -0.002447  11.335020  0.541339  49.568812  60.527210   0.0\n",
              "2107 -0.000163  0.001497  11.315980  0.610729  53.817202  57.446659   0.0\n",
              "2108 -0.000320 -0.000399  10.904662 -0.070423  48.176532  32.609183   0.0\n",
              "2109  0.002611  0.004077  11.234929  0.467651  54.352972  40.412307   1.0\n",
              "2110  0.006440  0.008354  11.849621 -0.047181  55.143488  47.275870   0.0\n",
              "\n",
              "[2111 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result01['Long'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOac_Yvge6Lv",
        "outputId": "96afab6e-bb49-47f0-8c74-c98b8c022c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2111"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(Day01))\n",
        "print(sum(Day02))\n",
        "print(sum(Day03))\n",
        "print(sum(Day04))\n",
        "print(sum(Day05))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUSownxYnTl7",
        "outputId": "8c092188-cd8b-4c56-cf1c-f2c859f0a931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "615\n",
            "628\n",
            "710\n",
            "1130\n",
            "777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def longCount(data, day):\n",
        "  point = 0\n",
        "  dayCount = 0\n",
        "  for i in range(len(data)):\n",
        "    if data['Long'][i] == 1:\n",
        "      dayCount = day[point]\n",
        "      point += 1\n",
        "    if dayCount > 0:\n",
        "      data['Long'][i] = 1\n",
        "      dayCount -= 1\n",
        "  return data"
      ],
      "metadata": {
        "id": "r0IWR4xdq3GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result01 = longCount(result01, Day01)\n",
        "result02 = longCount(result02, Day02)\n",
        "result03 = longCount(result03, Day03)\n",
        "result04 = longCount(result04, Day04)\n",
        "result05 = longCount(result05, Day05)"
      ],
      "metadata": {
        "id": "jw8anNk-xlwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result01['Long'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeoFp8D9m9ip",
        "outputId": "a728a5a6-a900-4c9b-9f1c-83dea8422903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1496\n",
              "1.0     615\n",
              "Name: Long, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from google.colab import drive\n",
        "from joblib import dump, load\n",
        "\n",
        "# Multi-layer Perceptron Classifier\n",
        "def MLPClassification(train,target,cols):\n",
        "  idx = int(len(train)*0.90)\n",
        "  x_train, x_test = train[:idx], train[idx:]\n",
        "  y_train, y_test = target[:idx], target[idx:]\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  train_scale = scaler.fit_transform(x_train)\n",
        "  test_scale = scaler.fit_transform(x_test)\n",
        "\n",
        "  mlp = MLPClassifier(hidden_layer_sizes=(10), activation = 'relu', solver = 'adam',max_iter= 10000, verbose = True)\n",
        "  mlp = mlp.fit(x_train, y_train)\n",
        "  predicted = mlp.predict(x_test)\n",
        "\n",
        "  return accuracy_score(y_test,predicted)\n",
        "\n",
        "# Processer Function\n",
        "def processingMedthod(df,cols):\n",
        "  train_data = df\n",
        "  train = train_data.drop(cols,axis=1).values\n",
        "  target = train_data[cols].values\n",
        "  accuracy = MLPClassification(train,target,cols)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "1iIDIzHrfu5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = []\n",
        "acc.append(processingMedthod(result01, 'Long'))\n",
        "acc.append(processingMedthod(result02, 'Long'))\n",
        "acc.append(processingMedthod(result03, 'Long'))\n",
        "acc.append(processingMedthod(result04, 'Long'))\n",
        "acc.append(processingMedthod(result05, 'Long'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOGPH2ROf9w_",
        "outputId": "9777d7b0-fcf6-4959-98c6-c930fbe53993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 3.09086307\n",
            "Iteration 2, loss = 2.49674348\n",
            "Iteration 3, loss = 1.95294598\n",
            "Iteration 4, loss = 1.50374812\n",
            "Iteration 5, loss = 1.23232232\n",
            "Iteration 6, loss = 1.11876745\n",
            "Iteration 7, loss = 1.05122916\n",
            "Iteration 8, loss = 0.98290957\n",
            "Iteration 9, loss = 0.92791026\n",
            "Iteration 10, loss = 0.87761496\n",
            "Iteration 11, loss = 0.83495860\n",
            "Iteration 12, loss = 0.79599728\n",
            "Iteration 13, loss = 0.76146291\n",
            "Iteration 14, loss = 0.73275230\n",
            "Iteration 15, loss = 0.70780464\n",
            "Iteration 16, loss = 0.68449200\n",
            "Iteration 17, loss = 0.66618111\n",
            "Iteration 18, loss = 0.64988080\n",
            "Iteration 19, loss = 0.63611516\n",
            "Iteration 20, loss = 0.62515864\n",
            "Iteration 21, loss = 0.61485619\n",
            "Iteration 22, loss = 0.60627826\n",
            "Iteration 23, loss = 0.59904103\n",
            "Iteration 24, loss = 0.59294637\n",
            "Iteration 25, loss = 0.58749892\n",
            "Iteration 26, loss = 0.58325081\n",
            "Iteration 27, loss = 0.57949944\n",
            "Iteration 28, loss = 0.57635106\n",
            "Iteration 29, loss = 0.57317741\n",
            "Iteration 30, loss = 0.57091071\n",
            "Iteration 31, loss = 0.56847478\n",
            "Iteration 32, loss = 0.56684434\n",
            "Iteration 33, loss = 0.56524586\n",
            "Iteration 34, loss = 0.56256982\n",
            "Iteration 35, loss = 0.56081051\n",
            "Iteration 36, loss = 0.55922252\n",
            "Iteration 37, loss = 0.55714048\n",
            "Iteration 38, loss = 0.55606495\n",
            "Iteration 39, loss = 0.55476599\n",
            "Iteration 40, loss = 0.55300920\n",
            "Iteration 41, loss = 0.55229016\n",
            "Iteration 42, loss = 0.55070413\n",
            "Iteration 43, loss = 0.54925874\n",
            "Iteration 44, loss = 0.54790562\n",
            "Iteration 45, loss = 0.54663871\n",
            "Iteration 46, loss = 0.54521161\n",
            "Iteration 47, loss = 0.54415125\n",
            "Iteration 48, loss = 0.54295047\n",
            "Iteration 49, loss = 0.54156358\n",
            "Iteration 50, loss = 0.54124136\n",
            "Iteration 51, loss = 0.54021679\n",
            "Iteration 52, loss = 0.53802564\n",
            "Iteration 53, loss = 0.53706339\n",
            "Iteration 54, loss = 0.53599284\n",
            "Iteration 55, loss = 0.53429662\n",
            "Iteration 56, loss = 0.53246318\n",
            "Iteration 57, loss = 0.52707671\n",
            "Iteration 58, loss = 0.52573868\n",
            "Iteration 59, loss = 0.52345959\n",
            "Iteration 60, loss = 0.52196649\n",
            "Iteration 61, loss = 0.51954604\n",
            "Iteration 62, loss = 0.51755755\n",
            "Iteration 63, loss = 0.51559085\n",
            "Iteration 64, loss = 0.51437338\n",
            "Iteration 65, loss = 0.51256490\n",
            "Iteration 66, loss = 0.51159909\n",
            "Iteration 67, loss = 0.50969219\n",
            "Iteration 68, loss = 0.51038042\n",
            "Iteration 69, loss = 0.50796240\n",
            "Iteration 70, loss = 0.50631670\n",
            "Iteration 71, loss = 0.50413493\n",
            "Iteration 72, loss = 0.50212681\n",
            "Iteration 73, loss = 0.50305890\n",
            "Iteration 74, loss = 0.50271026\n",
            "Iteration 75, loss = 0.49999461\n",
            "Iteration 76, loss = 0.49727970\n",
            "Iteration 77, loss = 0.49520056\n",
            "Iteration 78, loss = 0.49397519\n",
            "Iteration 79, loss = 0.49272047\n",
            "Iteration 80, loss = 0.49134400\n",
            "Iteration 81, loss = 0.49108357\n",
            "Iteration 82, loss = 0.48925381\n",
            "Iteration 83, loss = 0.48760309\n",
            "Iteration 84, loss = 0.48791364\n",
            "Iteration 85, loss = 0.48822012\n",
            "Iteration 86, loss = 0.49422001\n",
            "Iteration 87, loss = 0.48848258\n",
            "Iteration 88, loss = 0.48349068\n",
            "Iteration 89, loss = 0.48022278\n",
            "Iteration 90, loss = 0.47901071\n",
            "Iteration 91, loss = 0.47770622\n",
            "Iteration 92, loss = 0.47772258\n",
            "Iteration 93, loss = 0.47690433\n",
            "Iteration 94, loss = 0.47509461\n",
            "Iteration 95, loss = 0.47380396\n",
            "Iteration 96, loss = 0.47310432\n",
            "Iteration 97, loss = 0.47254809\n",
            "Iteration 98, loss = 0.47150208\n",
            "Iteration 99, loss = 0.46957938\n",
            "Iteration 100, loss = 0.46857205\n",
            "Iteration 101, loss = 0.46650989\n",
            "Iteration 102, loss = 0.46547665\n",
            "Iteration 103, loss = 0.46391831\n",
            "Iteration 104, loss = 0.46234756\n",
            "Iteration 105, loss = 0.46225467\n",
            "Iteration 106, loss = 0.46163816\n",
            "Iteration 107, loss = 0.45908813\n",
            "Iteration 108, loss = 0.45836917\n",
            "Iteration 109, loss = 0.45601348\n",
            "Iteration 110, loss = 0.45520104\n",
            "Iteration 111, loss = 0.45638904\n",
            "Iteration 112, loss = 0.45272823\n",
            "Iteration 113, loss = 0.45212519\n",
            "Iteration 114, loss = 0.45218544\n",
            "Iteration 115, loss = 0.45004311\n",
            "Iteration 116, loss = 0.44802322\n",
            "Iteration 117, loss = 0.44669979\n",
            "Iteration 118, loss = 0.44707976\n",
            "Iteration 119, loss = 0.44392361\n",
            "Iteration 120, loss = 0.44222220\n",
            "Iteration 121, loss = 0.44086685\n",
            "Iteration 122, loss = 0.43916036\n",
            "Iteration 123, loss = 0.43769034\n",
            "Iteration 124, loss = 0.43598333\n",
            "Iteration 125, loss = 0.43416301\n",
            "Iteration 126, loss = 0.43201550\n",
            "Iteration 127, loss = 0.42779883\n",
            "Iteration 128, loss = 0.42591173\n",
            "Iteration 129, loss = 0.41894246\n",
            "Iteration 130, loss = 0.41631719\n",
            "Iteration 131, loss = 0.41150772\n",
            "Iteration 132, loss = 0.40903443\n",
            "Iteration 133, loss = 0.42664355\n",
            "Iteration 134, loss = 0.40932540\n",
            "Iteration 135, loss = 0.39853927\n",
            "Iteration 136, loss = 0.39509853\n",
            "Iteration 137, loss = 0.39150794\n",
            "Iteration 138, loss = 0.38900627\n",
            "Iteration 139, loss = 0.38846375\n",
            "Iteration 140, loss = 0.38569586\n",
            "Iteration 141, loss = 0.38335677\n",
            "Iteration 142, loss = 0.38120564\n",
            "Iteration 143, loss = 0.38162906\n",
            "Iteration 144, loss = 0.37739083\n",
            "Iteration 145, loss = 0.37718880\n",
            "Iteration 146, loss = 0.37400263\n",
            "Iteration 147, loss = 0.37313305\n",
            "Iteration 148, loss = 0.37091764\n",
            "Iteration 149, loss = 0.37388267\n",
            "Iteration 150, loss = 0.36885935\n",
            "Iteration 151, loss = 0.36699762\n",
            "Iteration 152, loss = 0.36859211\n",
            "Iteration 153, loss = 0.36918754\n",
            "Iteration 154, loss = 0.36550328\n",
            "Iteration 155, loss = 0.36230922\n",
            "Iteration 156, loss = 0.36231771\n",
            "Iteration 157, loss = 0.36063375\n",
            "Iteration 158, loss = 0.36107541\n",
            "Iteration 159, loss = 0.35948357\n",
            "Iteration 160, loss = 0.35791388\n",
            "Iteration 161, loss = 0.36083624\n",
            "Iteration 162, loss = 0.35825815\n",
            "Iteration 163, loss = 0.36360502\n",
            "Iteration 164, loss = 0.35787637\n",
            "Iteration 165, loss = 0.35724502\n",
            "Iteration 166, loss = 0.35674535\n",
            "Iteration 167, loss = 0.34974522\n",
            "Iteration 168, loss = 0.34832776\n",
            "Iteration 169, loss = 0.34748083\n",
            "Iteration 170, loss = 0.34771844\n",
            "Iteration 171, loss = 0.34855555\n",
            "Iteration 172, loss = 0.34600056\n",
            "Iteration 173, loss = 0.34497212\n",
            "Iteration 174, loss = 0.34312799\n",
            "Iteration 175, loss = 0.34261183\n",
            "Iteration 176, loss = 0.34252222\n",
            "Iteration 177, loss = 0.34879359\n",
            "Iteration 178, loss = 0.34074418\n",
            "Iteration 179, loss = 0.33923272\n",
            "Iteration 180, loss = 0.33841466\n",
            "Iteration 181, loss = 0.33814485\n",
            "Iteration 182, loss = 0.33656508\n",
            "Iteration 183, loss = 0.33666463\n",
            "Iteration 184, loss = 0.33853088\n",
            "Iteration 185, loss = 0.34204158\n",
            "Iteration 186, loss = 0.33704186\n",
            "Iteration 187, loss = 0.33874162\n",
            "Iteration 188, loss = 0.33155774\n",
            "Iteration 189, loss = 0.33099608\n",
            "Iteration 190, loss = 0.33165397\n",
            "Iteration 191, loss = 0.33841031\n",
            "Iteration 192, loss = 0.33168439\n",
            "Iteration 193, loss = 0.33133217\n",
            "Iteration 194, loss = 0.32908034\n",
            "Iteration 195, loss = 0.32780226\n",
            "Iteration 196, loss = 0.33065193\n",
            "Iteration 197, loss = 0.33242950\n",
            "Iteration 198, loss = 0.32645639\n",
            "Iteration 199, loss = 0.32493524\n",
            "Iteration 200, loss = 0.32577886\n",
            "Iteration 201, loss = 0.32490780\n",
            "Iteration 202, loss = 0.32309899\n",
            "Iteration 203, loss = 0.32278771\n",
            "Iteration 204, loss = 0.32266816\n",
            "Iteration 205, loss = 0.32200683\n",
            "Iteration 206, loss = 0.32203186\n",
            "Iteration 207, loss = 0.32266111\n",
            "Iteration 208, loss = 0.32072214\n",
            "Iteration 209, loss = 0.31936376\n",
            "Iteration 210, loss = 0.32041463\n",
            "Iteration 211, loss = 0.32222060\n",
            "Iteration 212, loss = 0.31869250\n",
            "Iteration 213, loss = 0.32014930\n",
            "Iteration 214, loss = 0.31792594\n",
            "Iteration 215, loss = 0.31717404\n",
            "Iteration 216, loss = 0.31520792\n",
            "Iteration 217, loss = 0.31643326\n",
            "Iteration 218, loss = 0.31531258\n",
            "Iteration 219, loss = 0.31487657\n",
            "Iteration 220, loss = 0.31553669\n",
            "Iteration 221, loss = 0.31494966\n",
            "Iteration 222, loss = 0.31352068\n",
            "Iteration 223, loss = 0.31339469\n",
            "Iteration 224, loss = 0.31289216\n",
            "Iteration 225, loss = 0.31153422\n",
            "Iteration 226, loss = 0.31097077\n",
            "Iteration 227, loss = 0.31117072\n",
            "Iteration 228, loss = 0.31064464\n",
            "Iteration 229, loss = 0.30986259\n",
            "Iteration 230, loss = 0.30981020\n",
            "Iteration 231, loss = 0.30930677\n",
            "Iteration 232, loss = 0.31068654\n",
            "Iteration 233, loss = 0.30873631\n",
            "Iteration 234, loss = 0.30916287\n",
            "Iteration 235, loss = 0.30735889\n",
            "Iteration 236, loss = 0.30691956\n",
            "Iteration 237, loss = 0.30640715\n",
            "Iteration 238, loss = 0.30812117\n",
            "Iteration 239, loss = 0.30599894\n",
            "Iteration 240, loss = 0.30553288\n",
            "Iteration 241, loss = 0.30541572\n",
            "Iteration 242, loss = 0.30541847\n",
            "Iteration 243, loss = 0.30717757\n",
            "Iteration 244, loss = 0.30677381\n",
            "Iteration 245, loss = 0.30585082\n",
            "Iteration 246, loss = 0.30390981\n",
            "Iteration 247, loss = 0.30264876\n",
            "Iteration 248, loss = 0.30230469\n",
            "Iteration 249, loss = 0.30203646\n",
            "Iteration 250, loss = 0.30185283\n",
            "Iteration 251, loss = 0.30244942\n",
            "Iteration 252, loss = 0.30102752\n",
            "Iteration 253, loss = 0.30081905\n",
            "Iteration 254, loss = 0.30001197\n",
            "Iteration 255, loss = 0.29975996\n",
            "Iteration 256, loss = 0.29989632\n",
            "Iteration 257, loss = 0.30097931\n",
            "Iteration 258, loss = 0.29975793\n",
            "Iteration 259, loss = 0.29875559\n",
            "Iteration 260, loss = 0.29845532\n",
            "Iteration 261, loss = 0.29821706\n",
            "Iteration 262, loss = 0.29856772\n",
            "Iteration 263, loss = 0.29899777\n",
            "Iteration 264, loss = 0.29987187\n",
            "Iteration 265, loss = 0.29765156\n",
            "Iteration 266, loss = 0.29700061\n",
            "Iteration 267, loss = 0.29711267\n",
            "Iteration 268, loss = 0.29664663\n",
            "Iteration 269, loss = 0.29644694\n",
            "Iteration 270, loss = 0.29581528\n",
            "Iteration 271, loss = 0.29477915\n",
            "Iteration 272, loss = 0.29701337\n",
            "Iteration 273, loss = 0.29556954\n",
            "Iteration 274, loss = 0.29529706\n",
            "Iteration 275, loss = 0.29388750\n",
            "Iteration 276, loss = 0.29367649\n",
            "Iteration 277, loss = 0.29538397\n",
            "Iteration 278, loss = 0.29423177\n",
            "Iteration 279, loss = 0.29306935\n",
            "Iteration 280, loss = 0.29329728\n",
            "Iteration 281, loss = 0.29356808\n",
            "Iteration 282, loss = 0.29242740\n",
            "Iteration 283, loss = 0.29213306\n",
            "Iteration 284, loss = 0.29257228\n",
            "Iteration 285, loss = 0.29443713\n",
            "Iteration 286, loss = 0.29313827\n",
            "Iteration 287, loss = 0.29040682\n",
            "Iteration 288, loss = 0.29220804\n",
            "Iteration 289, loss = 0.29248653\n",
            "Iteration 290, loss = 0.29316766\n",
            "Iteration 291, loss = 0.29052214\n",
            "Iteration 292, loss = 0.29121491\n",
            "Iteration 293, loss = 0.29413851\n",
            "Iteration 294, loss = 0.29087862\n",
            "Iteration 295, loss = 0.29031361\n",
            "Iteration 296, loss = 0.28980939\n",
            "Iteration 297, loss = 0.28889285\n",
            "Iteration 298, loss = 0.28921656\n",
            "Iteration 299, loss = 0.29042694\n",
            "Iteration 300, loss = 0.29090013\n",
            "Iteration 301, loss = 0.28886466\n",
            "Iteration 302, loss = 0.28786207\n",
            "Iteration 303, loss = 0.28826952\n",
            "Iteration 304, loss = 0.29261222\n",
            "Iteration 305, loss = 0.29087110\n",
            "Iteration 306, loss = 0.29172316\n",
            "Iteration 307, loss = 0.29352701\n",
            "Iteration 308, loss = 0.28863702\n",
            "Iteration 309, loss = 0.28876004\n",
            "Iteration 310, loss = 0.28858509\n",
            "Iteration 311, loss = 0.29094830\n",
            "Iteration 312, loss = 0.28706913\n",
            "Iteration 313, loss = 0.28882530\n",
            "Iteration 314, loss = 0.29065186\n",
            "Iteration 315, loss = 0.28763901\n",
            "Iteration 316, loss = 0.29143010\n",
            "Iteration 317, loss = 0.29518664\n",
            "Iteration 318, loss = 0.28426237\n",
            "Iteration 319, loss = 0.28766189\n",
            "Iteration 320, loss = 0.28523966\n",
            "Iteration 321, loss = 0.28565559\n",
            "Iteration 322, loss = 0.28852159\n",
            "Iteration 323, loss = 0.28629715\n",
            "Iteration 324, loss = 0.28434020\n",
            "Iteration 325, loss = 0.28447910\n",
            "Iteration 326, loss = 0.28455123\n",
            "Iteration 327, loss = 0.28439314\n",
            "Iteration 328, loss = 0.28459497\n",
            "Iteration 329, loss = 0.28445849\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 12.86041495\n",
            "Iteration 2, loss = 10.81348606\n",
            "Iteration 3, loss = 8.80592011\n",
            "Iteration 4, loss = 6.85062967\n",
            "Iteration 5, loss = 4.99174053\n",
            "Iteration 6, loss = 3.40278797\n",
            "Iteration 7, loss = 2.30695454\n",
            "Iteration 8, loss = 1.79960111\n",
            "Iteration 9, loss = 1.62935545\n",
            "Iteration 10, loss = 1.50479992\n",
            "Iteration 11, loss = 1.38270373\n",
            "Iteration 12, loss = 1.27368775\n",
            "Iteration 13, loss = 1.19143445\n",
            "Iteration 14, loss = 1.12148789\n",
            "Iteration 15, loss = 1.06384675\n",
            "Iteration 16, loss = 1.01698181\n",
            "Iteration 17, loss = 0.97504118\n",
            "Iteration 18, loss = 0.93884950\n",
            "Iteration 19, loss = 0.90818853\n",
            "Iteration 20, loss = 0.87905209\n",
            "Iteration 21, loss = 0.85256632\n",
            "Iteration 22, loss = 0.82934835\n",
            "Iteration 23, loss = 0.80674000\n",
            "Iteration 24, loss = 0.78498756\n",
            "Iteration 25, loss = 0.76426017\n",
            "Iteration 26, loss = 0.74451866\n",
            "Iteration 27, loss = 0.72328788\n",
            "Iteration 28, loss = 0.70258397\n",
            "Iteration 29, loss = 0.68138685\n",
            "Iteration 30, loss = 0.66105417\n",
            "Iteration 31, loss = 0.64165218\n",
            "Iteration 32, loss = 0.62152203\n",
            "Iteration 33, loss = 0.60245270\n",
            "Iteration 34, loss = 0.58396249\n",
            "Iteration 35, loss = 0.56638423\n",
            "Iteration 36, loss = 0.54954685\n",
            "Iteration 37, loss = 0.53496501\n",
            "Iteration 38, loss = 0.51834290\n",
            "Iteration 39, loss = 0.50326177\n",
            "Iteration 40, loss = 0.49040384\n",
            "Iteration 41, loss = 0.47837166\n",
            "Iteration 42, loss = 0.46860433\n",
            "Iteration 43, loss = 0.45515786\n",
            "Iteration 44, loss = 0.44061527\n",
            "Iteration 45, loss = 0.42832049\n",
            "Iteration 46, loss = 0.41808577\n",
            "Iteration 47, loss = 0.40626850\n",
            "Iteration 48, loss = 0.39664643\n",
            "Iteration 49, loss = 0.38877102\n",
            "Iteration 50, loss = 0.38218159\n",
            "Iteration 51, loss = 0.37546085\n",
            "Iteration 52, loss = 0.37042599\n",
            "Iteration 53, loss = 0.36446276\n",
            "Iteration 54, loss = 0.35935566\n",
            "Iteration 55, loss = 0.35497909\n",
            "Iteration 56, loss = 0.35208476\n",
            "Iteration 57, loss = 0.34761511\n",
            "Iteration 58, loss = 0.34308363\n",
            "Iteration 59, loss = 0.33660631\n",
            "Iteration 60, loss = 0.33437177\n",
            "Iteration 61, loss = 0.33113899\n",
            "Iteration 62, loss = 0.32697852\n",
            "Iteration 63, loss = 0.32373741\n",
            "Iteration 64, loss = 0.32163724\n",
            "Iteration 65, loss = 0.31867839\n",
            "Iteration 66, loss = 0.31690409\n",
            "Iteration 67, loss = 0.31277517\n",
            "Iteration 68, loss = 0.31090766\n",
            "Iteration 69, loss = 0.30769712\n",
            "Iteration 70, loss = 0.30529702\n",
            "Iteration 71, loss = 0.30370975\n",
            "Iteration 72, loss = 0.30217440\n",
            "Iteration 73, loss = 0.29964815\n",
            "Iteration 74, loss = 0.29821585\n",
            "Iteration 75, loss = 0.29890184\n",
            "Iteration 76, loss = 0.29538704\n",
            "Iteration 77, loss = 0.29262541\n",
            "Iteration 78, loss = 0.29107614\n",
            "Iteration 79, loss = 0.29004630\n",
            "Iteration 80, loss = 0.28842321\n",
            "Iteration 81, loss = 0.28703338\n",
            "Iteration 82, loss = 0.28922259\n",
            "Iteration 83, loss = 0.28880604\n",
            "Iteration 84, loss = 0.28491946\n",
            "Iteration 85, loss = 0.28305225\n",
            "Iteration 86, loss = 0.28271955\n",
            "Iteration 87, loss = 0.28088664\n",
            "Iteration 88, loss = 0.28043370\n",
            "Iteration 89, loss = 0.27913786\n",
            "Iteration 90, loss = 0.27781720\n",
            "Iteration 91, loss = 0.27731022\n",
            "Iteration 92, loss = 0.27684969\n",
            "Iteration 93, loss = 0.27590601\n",
            "Iteration 94, loss = 0.27522500\n",
            "Iteration 95, loss = 0.27396735\n",
            "Iteration 96, loss = 0.27375166\n",
            "Iteration 97, loss = 0.27318294\n",
            "Iteration 98, loss = 0.27271840\n",
            "Iteration 99, loss = 0.27264101\n",
            "Iteration 100, loss = 0.27148610\n",
            "Iteration 101, loss = 0.27021309\n",
            "Iteration 102, loss = 0.27018009\n",
            "Iteration 103, loss = 0.26896284\n",
            "Iteration 104, loss = 0.26964505\n",
            "Iteration 105, loss = 0.26816875\n",
            "Iteration 106, loss = 0.26789068\n",
            "Iteration 107, loss = 0.26829723\n",
            "Iteration 108, loss = 0.26660974\n",
            "Iteration 109, loss = 0.26641904\n",
            "Iteration 110, loss = 0.26592532\n",
            "Iteration 111, loss = 0.26549512\n",
            "Iteration 112, loss = 0.26496988\n",
            "Iteration 113, loss = 0.26610005\n",
            "Iteration 114, loss = 0.26578461\n",
            "Iteration 115, loss = 0.26432042\n",
            "Iteration 116, loss = 0.26310384\n",
            "Iteration 117, loss = 0.26313497\n",
            "Iteration 118, loss = 0.26261107\n",
            "Iteration 119, loss = 0.26227691\n",
            "Iteration 120, loss = 0.26149823\n",
            "Iteration 121, loss = 0.26170401\n",
            "Iteration 122, loss = 0.26150334\n",
            "Iteration 123, loss = 0.26111616\n",
            "Iteration 124, loss = 0.26226503\n",
            "Iteration 125, loss = 0.26105444\n",
            "Iteration 126, loss = 0.26055151\n",
            "Iteration 127, loss = 0.26010199\n",
            "Iteration 128, loss = 0.25882059\n",
            "Iteration 129, loss = 0.26264576\n",
            "Iteration 130, loss = 0.26016507\n",
            "Iteration 131, loss = 0.25886751\n",
            "Iteration 132, loss = 0.25890134\n",
            "Iteration 133, loss = 0.25886546\n",
            "Iteration 134, loss = 0.25852474\n",
            "Iteration 135, loss = 0.25831240\n",
            "Iteration 136, loss = 0.25813394\n",
            "Iteration 137, loss = 0.25797461\n",
            "Iteration 138, loss = 0.25781090\n",
            "Iteration 139, loss = 0.25786320\n",
            "Iteration 140, loss = 0.25744046\n",
            "Iteration 141, loss = 0.25734307\n",
            "Iteration 142, loss = 0.25715278\n",
            "Iteration 143, loss = 0.25703683\n",
            "Iteration 144, loss = 0.25726997\n",
            "Iteration 145, loss = 0.25843801\n",
            "Iteration 146, loss = 0.25686952\n",
            "Iteration 147, loss = 0.25756098\n",
            "Iteration 148, loss = 0.25713113\n",
            "Iteration 149, loss = 0.25690153\n",
            "Iteration 150, loss = 0.25636671\n",
            "Iteration 151, loss = 0.25720568\n",
            "Iteration 152, loss = 0.25607183\n",
            "Iteration 153, loss = 0.25613807\n",
            "Iteration 154, loss = 0.25715287\n",
            "Iteration 155, loss = 0.25762894\n",
            "Iteration 156, loss = 0.25755010\n",
            "Iteration 157, loss = 0.25514755\n",
            "Iteration 158, loss = 0.25652970\n",
            "Iteration 159, loss = 0.25763418\n",
            "Iteration 160, loss = 0.25594785\n",
            "Iteration 161, loss = 0.25531186\n",
            "Iteration 162, loss = 0.25604484\n",
            "Iteration 163, loss = 0.25519189\n",
            "Iteration 164, loss = 0.25570260\n",
            "Iteration 165, loss = 0.25490792\n",
            "Iteration 166, loss = 0.25493308\n",
            "Iteration 167, loss = 0.25466359\n",
            "Iteration 168, loss = 0.25518713\n",
            "Iteration 169, loss = 0.25425003\n",
            "Iteration 170, loss = 0.25363824\n",
            "Iteration 171, loss = 0.25411979\n",
            "Iteration 172, loss = 0.25380689\n",
            "Iteration 173, loss = 0.25389203\n",
            "Iteration 174, loss = 0.25335478\n",
            "Iteration 175, loss = 0.25468098\n",
            "Iteration 176, loss = 0.25400730\n",
            "Iteration 177, loss = 0.25460801\n",
            "Iteration 178, loss = 0.25431929\n",
            "Iteration 179, loss = 0.25434714\n",
            "Iteration 180, loss = 0.25287487\n",
            "Iteration 181, loss = 0.25309648\n",
            "Iteration 182, loss = 0.25275572\n",
            "Iteration 183, loss = 0.25295843\n",
            "Iteration 184, loss = 0.25354359\n",
            "Iteration 185, loss = 0.25434162\n",
            "Iteration 186, loss = 0.25316905\n",
            "Iteration 187, loss = 0.25308413\n",
            "Iteration 188, loss = 0.25311248\n",
            "Iteration 189, loss = 0.25325675\n",
            "Iteration 190, loss = 0.25380367\n",
            "Iteration 191, loss = 0.25482807\n",
            "Iteration 192, loss = 0.25512321\n",
            "Iteration 193, loss = 0.25197816\n",
            "Iteration 194, loss = 0.25232380\n",
            "Iteration 195, loss = 0.25242438\n",
            "Iteration 196, loss = 0.25157666\n",
            "Iteration 197, loss = 0.25194331\n",
            "Iteration 198, loss = 0.25245116\n",
            "Iteration 199, loss = 0.25148790\n",
            "Iteration 200, loss = 0.25186423\n",
            "Iteration 201, loss = 0.25194540\n",
            "Iteration 202, loss = 0.25191509\n",
            "Iteration 203, loss = 0.25136979\n",
            "Iteration 204, loss = 0.25092705\n",
            "Iteration 205, loss = 0.25119815\n",
            "Iteration 206, loss = 0.25120754\n",
            "Iteration 207, loss = 0.25092865\n",
            "Iteration 208, loss = 0.25088269\n",
            "Iteration 209, loss = 0.25131684\n",
            "Iteration 210, loss = 0.25083296\n",
            "Iteration 211, loss = 0.25128730\n",
            "Iteration 212, loss = 0.25098843\n",
            "Iteration 213, loss = 0.25240528\n",
            "Iteration 214, loss = 0.25125676\n",
            "Iteration 215, loss = 0.25064227\n",
            "Iteration 216, loss = 0.25166409\n",
            "Iteration 217, loss = 0.25054485\n",
            "Iteration 218, loss = 0.25004449\n",
            "Iteration 219, loss = 0.24999865\n",
            "Iteration 220, loss = 0.25057656\n",
            "Iteration 221, loss = 0.25034352\n",
            "Iteration 222, loss = 0.25199977\n",
            "Iteration 223, loss = 0.25002814\n",
            "Iteration 224, loss = 0.24973681\n",
            "Iteration 225, loss = 0.24971473\n",
            "Iteration 226, loss = 0.24997523\n",
            "Iteration 227, loss = 0.25075565\n",
            "Iteration 228, loss = 0.25130057\n",
            "Iteration 229, loss = 0.25094809\n",
            "Iteration 230, loss = 0.25327037\n",
            "Iteration 231, loss = 0.25195546\n",
            "Iteration 232, loss = 0.24993369\n",
            "Iteration 233, loss = 0.25028367\n",
            "Iteration 234, loss = 0.24972414\n",
            "Iteration 235, loss = 0.25005584\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.06796958\n",
            "Iteration 2, loss = 0.85768341\n",
            "Iteration 3, loss = 0.75335438\n",
            "Iteration 4, loss = 0.68755214\n",
            "Iteration 5, loss = 0.66488072\n",
            "Iteration 6, loss = 0.65198500\n",
            "Iteration 7, loss = 0.64132951\n",
            "Iteration 8, loss = 0.63273790\n",
            "Iteration 9, loss = 0.62445691\n",
            "Iteration 10, loss = 0.61777124\n",
            "Iteration 11, loss = 0.61051259\n",
            "Iteration 12, loss = 0.60385414\n",
            "Iteration 13, loss = 0.59798921\n",
            "Iteration 14, loss = 0.59268001\n",
            "Iteration 15, loss = 0.58649950\n",
            "Iteration 16, loss = 0.58074525\n",
            "Iteration 17, loss = 0.57464155\n",
            "Iteration 18, loss = 0.56701113\n",
            "Iteration 19, loss = 0.55801486\n",
            "Iteration 20, loss = 0.54934560\n",
            "Iteration 21, loss = 0.53958856\n",
            "Iteration 22, loss = 0.53167544\n",
            "Iteration 23, loss = 0.52193313\n",
            "Iteration 24, loss = 0.51130704\n",
            "Iteration 25, loss = 0.50356887\n",
            "Iteration 26, loss = 0.49542190\n",
            "Iteration 27, loss = 0.49072704\n",
            "Iteration 28, loss = 0.48380216\n",
            "Iteration 29, loss = 0.47945456\n",
            "Iteration 30, loss = 0.47523665\n",
            "Iteration 31, loss = 0.47501821\n",
            "Iteration 32, loss = 0.47317859\n",
            "Iteration 33, loss = 0.46988546\n",
            "Iteration 34, loss = 0.46561391\n",
            "Iteration 35, loss = 0.46215200\n",
            "Iteration 36, loss = 0.45796964\n",
            "Iteration 37, loss = 0.45564444\n",
            "Iteration 38, loss = 0.45342750\n",
            "Iteration 39, loss = 0.45161426\n",
            "Iteration 40, loss = 0.44912853\n",
            "Iteration 41, loss = 0.44742224\n",
            "Iteration 42, loss = 0.44663226\n",
            "Iteration 43, loss = 0.44733853\n",
            "Iteration 44, loss = 0.44382845\n",
            "Iteration 45, loss = 0.44073214\n",
            "Iteration 46, loss = 0.44083264\n",
            "Iteration 47, loss = 0.44017184\n",
            "Iteration 48, loss = 0.43560638\n",
            "Iteration 49, loss = 0.43506698\n",
            "Iteration 50, loss = 0.43321434\n",
            "Iteration 51, loss = 0.43148156\n",
            "Iteration 52, loss = 0.43055719\n",
            "Iteration 53, loss = 0.42874091\n",
            "Iteration 54, loss = 0.42715529\n",
            "Iteration 55, loss = 0.42660886\n",
            "Iteration 56, loss = 0.42389210\n",
            "Iteration 57, loss = 0.42368796\n",
            "Iteration 58, loss = 0.42144283\n",
            "Iteration 59, loss = 0.41938906\n",
            "Iteration 60, loss = 0.41900293\n",
            "Iteration 61, loss = 0.41815264\n",
            "Iteration 62, loss = 0.41707782\n",
            "Iteration 63, loss = 0.42047021\n",
            "Iteration 64, loss = 0.41411148\n",
            "Iteration 65, loss = 0.41611732\n",
            "Iteration 66, loss = 0.41181539\n",
            "Iteration 67, loss = 0.41240453\n",
            "Iteration 68, loss = 0.41737987\n",
            "Iteration 69, loss = 0.40766176\n",
            "Iteration 70, loss = 0.40604457\n",
            "Iteration 71, loss = 0.40457859\n",
            "Iteration 72, loss = 0.40411262\n",
            "Iteration 73, loss = 0.40426402\n",
            "Iteration 74, loss = 0.40076106\n",
            "Iteration 75, loss = 0.39979974\n",
            "Iteration 76, loss = 0.39948291\n",
            "Iteration 77, loss = 0.39745509\n",
            "Iteration 78, loss = 0.39801933\n",
            "Iteration 79, loss = 0.39928243\n",
            "Iteration 80, loss = 0.39379429\n",
            "Iteration 81, loss = 0.39416315\n",
            "Iteration 82, loss = 0.39292627\n",
            "Iteration 83, loss = 0.39222371\n",
            "Iteration 84, loss = 0.39044670\n",
            "Iteration 85, loss = 0.38904765\n",
            "Iteration 86, loss = 0.39021403\n",
            "Iteration 87, loss = 0.38638821\n",
            "Iteration 88, loss = 0.38708016\n",
            "Iteration 89, loss = 0.39031780\n",
            "Iteration 90, loss = 0.38400045\n",
            "Iteration 91, loss = 0.38625935\n",
            "Iteration 92, loss = 0.38522734\n",
            "Iteration 93, loss = 0.38261436\n",
            "Iteration 94, loss = 0.38137979\n",
            "Iteration 95, loss = 0.37902716\n",
            "Iteration 96, loss = 0.38133461\n",
            "Iteration 97, loss = 0.38083938\n",
            "Iteration 98, loss = 0.37884333\n",
            "Iteration 99, loss = 0.37642455\n",
            "Iteration 100, loss = 0.37411600\n",
            "Iteration 101, loss = 0.37334605\n",
            "Iteration 102, loss = 0.37468954\n",
            "Iteration 103, loss = 0.37142570\n",
            "Iteration 104, loss = 0.37080654\n",
            "Iteration 105, loss = 0.36948260\n",
            "Iteration 106, loss = 0.36843458\n",
            "Iteration 107, loss = 0.36749656\n",
            "Iteration 108, loss = 0.36849117\n",
            "Iteration 109, loss = 0.36774987\n",
            "Iteration 110, loss = 0.36473525\n",
            "Iteration 111, loss = 0.36421303\n",
            "Iteration 112, loss = 0.36461075\n",
            "Iteration 113, loss = 0.36355460\n",
            "Iteration 114, loss = 0.36145441\n",
            "Iteration 115, loss = 0.35988278\n",
            "Iteration 116, loss = 0.36032483\n",
            "Iteration 117, loss = 0.36059920\n",
            "Iteration 118, loss = 0.35705773\n",
            "Iteration 119, loss = 0.35586894\n",
            "Iteration 120, loss = 0.35470685\n",
            "Iteration 121, loss = 0.35393307\n",
            "Iteration 122, loss = 0.35296177\n",
            "Iteration 123, loss = 0.35199638\n",
            "Iteration 124, loss = 0.35061462\n",
            "Iteration 125, loss = 0.34974232\n",
            "Iteration 126, loss = 0.34937962\n",
            "Iteration 127, loss = 0.34898640\n",
            "Iteration 128, loss = 0.34968619\n",
            "Iteration 129, loss = 0.34810009\n",
            "Iteration 130, loss = 0.34751366\n",
            "Iteration 131, loss = 0.34583184\n",
            "Iteration 132, loss = 0.34468186\n",
            "Iteration 133, loss = 0.34356502\n",
            "Iteration 134, loss = 0.34277402\n",
            "Iteration 135, loss = 0.34133660\n",
            "Iteration 136, loss = 0.34035141\n",
            "Iteration 137, loss = 0.34024092\n",
            "Iteration 138, loss = 0.34140979\n",
            "Iteration 139, loss = 0.33824190\n",
            "Iteration 140, loss = 0.33680944\n",
            "Iteration 141, loss = 0.33791866\n",
            "Iteration 142, loss = 0.33632013\n",
            "Iteration 143, loss = 0.33820887\n",
            "Iteration 144, loss = 0.33783234\n",
            "Iteration 145, loss = 0.33522768\n",
            "Iteration 146, loss = 0.33850880\n",
            "Iteration 147, loss = 0.33548521\n",
            "Iteration 148, loss = 0.33559467\n",
            "Iteration 149, loss = 0.33125335\n",
            "Iteration 150, loss = 0.33278838\n",
            "Iteration 151, loss = 0.33310636\n",
            "Iteration 152, loss = 0.33066693\n",
            "Iteration 153, loss = 0.32996184\n",
            "Iteration 154, loss = 0.33276877\n",
            "Iteration 155, loss = 0.33030266\n",
            "Iteration 156, loss = 0.32757446\n",
            "Iteration 157, loss = 0.32846780\n",
            "Iteration 158, loss = 0.32940399\n",
            "Iteration 159, loss = 0.33050467\n",
            "Iteration 160, loss = 0.33311483\n",
            "Iteration 161, loss = 0.33028070\n",
            "Iteration 162, loss = 0.32540633\n",
            "Iteration 163, loss = 0.32847440\n",
            "Iteration 164, loss = 0.32569012\n",
            "Iteration 165, loss = 0.32484153\n",
            "Iteration 166, loss = 0.32462546\n",
            "Iteration 167, loss = 0.32361856\n",
            "Iteration 168, loss = 0.32417514\n",
            "Iteration 169, loss = 0.32308407\n",
            "Iteration 170, loss = 0.32245445\n",
            "Iteration 171, loss = 0.33010790\n",
            "Iteration 172, loss = 0.32864076\n",
            "Iteration 173, loss = 0.32180868\n",
            "Iteration 174, loss = 0.32152368\n",
            "Iteration 175, loss = 0.32051554\n",
            "Iteration 176, loss = 0.32378864\n",
            "Iteration 177, loss = 0.32050040\n",
            "Iteration 178, loss = 0.32059467\n",
            "Iteration 179, loss = 0.31916751\n",
            "Iteration 180, loss = 0.32144066\n",
            "Iteration 181, loss = 0.32208203\n",
            "Iteration 182, loss = 0.32492234\n",
            "Iteration 183, loss = 0.32749768\n",
            "Iteration 184, loss = 0.32129779\n",
            "Iteration 185, loss = 0.31956191\n",
            "Iteration 186, loss = 0.31691594\n",
            "Iteration 187, loss = 0.31711257\n",
            "Iteration 188, loss = 0.31611439\n",
            "Iteration 189, loss = 0.31643578\n",
            "Iteration 190, loss = 0.31634850\n",
            "Iteration 191, loss = 0.32438328\n",
            "Iteration 192, loss = 0.31733346\n",
            "Iteration 193, loss = 0.32015058\n",
            "Iteration 194, loss = 0.31542247\n",
            "Iteration 195, loss = 0.31698016\n",
            "Iteration 196, loss = 0.31716023\n",
            "Iteration 197, loss = 0.31447412\n",
            "Iteration 198, loss = 0.31419285\n",
            "Iteration 199, loss = 0.31453130\n",
            "Iteration 200, loss = 0.31447464\n",
            "Iteration 201, loss = 0.31367691\n",
            "Iteration 202, loss = 0.31509619\n",
            "Iteration 203, loss = 0.31604595\n",
            "Iteration 204, loss = 0.31380506\n",
            "Iteration 205, loss = 0.31549352\n",
            "Iteration 206, loss = 0.31587226\n",
            "Iteration 207, loss = 0.31336045\n",
            "Iteration 208, loss = 0.31422350\n",
            "Iteration 209, loss = 0.31399649\n",
            "Iteration 210, loss = 0.31174678\n",
            "Iteration 211, loss = 0.31673872\n",
            "Iteration 212, loss = 0.31162726\n",
            "Iteration 213, loss = 0.31234552\n",
            "Iteration 214, loss = 0.31447757\n",
            "Iteration 215, loss = 0.31921787\n",
            "Iteration 216, loss = 0.31448394\n",
            "Iteration 217, loss = 0.31165507\n",
            "Iteration 218, loss = 0.31415179\n",
            "Iteration 219, loss = 0.31179966\n",
            "Iteration 220, loss = 0.31367513\n",
            "Iteration 221, loss = 0.31448227\n",
            "Iteration 222, loss = 0.31437458\n",
            "Iteration 223, loss = 0.31261751\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 4.84626806\n",
            "Iteration 2, loss = 4.10615808\n",
            "Iteration 3, loss = 3.61383025\n",
            "Iteration 4, loss = 3.34777278\n",
            "Iteration 5, loss = 3.19251652\n",
            "Iteration 6, loss = 3.08155591\n",
            "Iteration 7, loss = 2.95890560\n",
            "Iteration 8, loss = 2.82914336\n",
            "Iteration 9, loss = 2.67727484\n",
            "Iteration 10, loss = 2.50457337\n",
            "Iteration 11, loss = 2.32117972\n",
            "Iteration 12, loss = 2.15128508\n",
            "Iteration 13, loss = 1.99604173\n",
            "Iteration 14, loss = 1.86321269\n",
            "Iteration 15, loss = 1.74941729\n",
            "Iteration 16, loss = 1.65400000\n",
            "Iteration 17, loss = 1.57432937\n",
            "Iteration 18, loss = 1.50020246\n",
            "Iteration 19, loss = 1.43152204\n",
            "Iteration 20, loss = 1.37238813\n",
            "Iteration 21, loss = 1.31314028\n",
            "Iteration 22, loss = 1.26004209\n",
            "Iteration 23, loss = 1.20538681\n",
            "Iteration 24, loss = 1.15416451\n",
            "Iteration 25, loss = 1.08869450\n",
            "Iteration 26, loss = 1.02430947\n",
            "Iteration 27, loss = 0.96242153\n",
            "Iteration 28, loss = 0.89698804\n",
            "Iteration 29, loss = 0.83952331\n",
            "Iteration 30, loss = 0.78407693\n",
            "Iteration 31, loss = 0.73675219\n",
            "Iteration 32, loss = 0.69363212\n",
            "Iteration 33, loss = 0.65892692\n",
            "Iteration 34, loss = 0.63366241\n",
            "Iteration 35, loss = 0.61267467\n",
            "Iteration 36, loss = 0.59457187\n",
            "Iteration 37, loss = 0.58180111\n",
            "Iteration 38, loss = 0.57419755\n",
            "Iteration 39, loss = 0.56666832\n",
            "Iteration 40, loss = 0.55849744\n",
            "Iteration 41, loss = 0.55205986\n",
            "Iteration 42, loss = 0.54920165\n",
            "Iteration 43, loss = 0.54702127\n",
            "Iteration 44, loss = 0.54063196\n",
            "Iteration 45, loss = 0.53653291\n",
            "Iteration 46, loss = 0.53369396\n",
            "Iteration 47, loss = 0.53096306\n",
            "Iteration 48, loss = 0.52920760\n",
            "Iteration 49, loss = 0.52458618\n",
            "Iteration 50, loss = 0.52185813\n",
            "Iteration 51, loss = 0.52155082\n",
            "Iteration 52, loss = 0.51627770\n",
            "Iteration 53, loss = 0.51569177\n",
            "Iteration 54, loss = 0.51488566\n",
            "Iteration 55, loss = 0.51225264\n",
            "Iteration 56, loss = 0.50821287\n",
            "Iteration 57, loss = 0.50482493\n",
            "Iteration 58, loss = 0.50377250\n",
            "Iteration 59, loss = 0.50111162\n",
            "Iteration 60, loss = 0.49852990\n",
            "Iteration 61, loss = 0.49610266\n",
            "Iteration 62, loss = 0.49398999\n",
            "Iteration 63, loss = 0.49237265\n",
            "Iteration 64, loss = 0.49000280\n",
            "Iteration 65, loss = 0.48808679\n",
            "Iteration 66, loss = 0.48587790\n",
            "Iteration 67, loss = 0.48373245\n",
            "Iteration 68, loss = 0.48213216\n",
            "Iteration 69, loss = 0.48023146\n",
            "Iteration 70, loss = 0.47797488\n",
            "Iteration 71, loss = 0.47646327\n",
            "Iteration 72, loss = 0.47627673\n",
            "Iteration 73, loss = 0.47351621\n",
            "Iteration 74, loss = 0.47180174\n",
            "Iteration 75, loss = 0.46904758\n",
            "Iteration 76, loss = 0.46831667\n",
            "Iteration 77, loss = 0.46709737\n",
            "Iteration 78, loss = 0.46392259\n",
            "Iteration 79, loss = 0.46217097\n",
            "Iteration 80, loss = 0.46010739\n",
            "Iteration 81, loss = 0.45857570\n",
            "Iteration 82, loss = 0.45672064\n",
            "Iteration 83, loss = 0.45561709\n",
            "Iteration 84, loss = 0.45367382\n",
            "Iteration 85, loss = 0.45107943\n",
            "Iteration 86, loss = 0.45040896\n",
            "Iteration 87, loss = 0.44827878\n",
            "Iteration 88, loss = 0.44760755\n",
            "Iteration 89, loss = 0.44549391\n",
            "Iteration 90, loss = 0.44552939\n",
            "Iteration 91, loss = 0.44490700\n",
            "Iteration 92, loss = 0.44337289\n",
            "Iteration 93, loss = 0.44054043\n",
            "Iteration 94, loss = 0.44210747\n",
            "Iteration 95, loss = 0.44164081\n",
            "Iteration 96, loss = 0.43593467\n",
            "Iteration 97, loss = 0.43414934\n",
            "Iteration 98, loss = 0.43270951\n",
            "Iteration 99, loss = 0.43202353\n",
            "Iteration 100, loss = 0.43140886\n",
            "Iteration 101, loss = 0.42791325\n",
            "Iteration 102, loss = 0.42495106\n",
            "Iteration 103, loss = 0.42403175\n",
            "Iteration 104, loss = 0.42247539\n",
            "Iteration 105, loss = 0.42157255\n",
            "Iteration 106, loss = 0.42151186\n",
            "Iteration 107, loss = 0.42071801\n",
            "Iteration 108, loss = 0.41823209\n",
            "Iteration 109, loss = 0.41640823\n",
            "Iteration 110, loss = 0.41562605\n",
            "Iteration 111, loss = 0.41608622\n",
            "Iteration 112, loss = 0.41281726\n",
            "Iteration 113, loss = 0.41254348\n",
            "Iteration 114, loss = 0.41040764\n",
            "Iteration 115, loss = 0.40703325\n",
            "Iteration 116, loss = 0.40617087\n",
            "Iteration 117, loss = 0.40454246\n",
            "Iteration 118, loss = 0.40363493\n",
            "Iteration 119, loss = 0.40188140\n",
            "Iteration 120, loss = 0.40422249\n",
            "Iteration 121, loss = 0.39925198\n",
            "Iteration 122, loss = 0.39979894\n",
            "Iteration 123, loss = 0.39687516\n",
            "Iteration 124, loss = 0.39789599\n",
            "Iteration 125, loss = 0.39449169\n",
            "Iteration 126, loss = 0.39312599\n",
            "Iteration 127, loss = 0.39252481\n",
            "Iteration 128, loss = 0.39093227\n",
            "Iteration 129, loss = 0.38988465\n",
            "Iteration 130, loss = 0.38764943\n",
            "Iteration 131, loss = 0.38715906\n",
            "Iteration 132, loss = 0.38662738\n",
            "Iteration 133, loss = 0.38547356\n",
            "Iteration 134, loss = 0.38553759\n",
            "Iteration 135, loss = 0.38420732\n",
            "Iteration 136, loss = 0.38106420\n",
            "Iteration 137, loss = 0.38051386\n",
            "Iteration 138, loss = 0.37931685\n",
            "Iteration 139, loss = 0.37883246\n",
            "Iteration 140, loss = 0.37910573\n",
            "Iteration 141, loss = 0.37506139\n",
            "Iteration 142, loss = 0.37653016\n",
            "Iteration 143, loss = 0.37421849\n",
            "Iteration 144, loss = 0.37608817\n",
            "Iteration 145, loss = 0.37122951\n",
            "Iteration 146, loss = 0.37175223\n",
            "Iteration 147, loss = 0.36969876\n",
            "Iteration 148, loss = 0.36961442\n",
            "Iteration 149, loss = 0.36778159\n",
            "Iteration 150, loss = 0.36655638\n",
            "Iteration 151, loss = 0.36551939\n",
            "Iteration 152, loss = 0.36543902\n",
            "Iteration 153, loss = 0.36521705\n",
            "Iteration 154, loss = 0.36413977\n",
            "Iteration 155, loss = 0.36306734\n",
            "Iteration 156, loss = 0.36263619\n",
            "Iteration 157, loss = 0.36069224\n",
            "Iteration 158, loss = 0.35868549\n",
            "Iteration 159, loss = 0.35963894\n",
            "Iteration 160, loss = 0.35744366\n",
            "Iteration 161, loss = 0.35632160\n",
            "Iteration 162, loss = 0.35637791\n",
            "Iteration 163, loss = 0.35588041\n",
            "Iteration 164, loss = 0.35599835\n",
            "Iteration 165, loss = 0.35764185\n",
            "Iteration 166, loss = 0.35331105\n",
            "Iteration 167, loss = 0.35254704\n",
            "Iteration 168, loss = 0.35270964\n",
            "Iteration 169, loss = 0.34981213\n",
            "Iteration 170, loss = 0.35188937\n",
            "Iteration 171, loss = 0.34971206\n",
            "Iteration 172, loss = 0.34837888\n",
            "Iteration 173, loss = 0.34724033\n",
            "Iteration 174, loss = 0.34732651\n",
            "Iteration 175, loss = 0.34584695\n",
            "Iteration 176, loss = 0.34450887\n",
            "Iteration 177, loss = 0.34431803\n",
            "Iteration 178, loss = 0.34636889\n",
            "Iteration 179, loss = 0.34244003\n",
            "Iteration 180, loss = 0.34320715\n",
            "Iteration 181, loss = 0.34191818\n",
            "Iteration 182, loss = 0.34062596\n",
            "Iteration 183, loss = 0.33955491\n",
            "Iteration 184, loss = 0.33864549\n",
            "Iteration 185, loss = 0.33876121\n",
            "Iteration 186, loss = 0.33863305\n",
            "Iteration 187, loss = 0.33709643\n",
            "Iteration 188, loss = 0.33865867\n",
            "Iteration 189, loss = 0.34297937\n",
            "Iteration 190, loss = 0.33741240\n",
            "Iteration 191, loss = 0.33693384\n",
            "Iteration 192, loss = 0.33361404\n",
            "Iteration 193, loss = 0.33775723\n",
            "Iteration 194, loss = 0.33791274\n",
            "Iteration 195, loss = 0.33679827\n",
            "Iteration 196, loss = 0.33210020\n",
            "Iteration 197, loss = 0.33148254\n",
            "Iteration 198, loss = 0.33098978\n",
            "Iteration 199, loss = 0.33030649\n",
            "Iteration 200, loss = 0.32992136\n",
            "Iteration 201, loss = 0.32960481\n",
            "Iteration 202, loss = 0.32858020\n",
            "Iteration 203, loss = 0.32867965\n",
            "Iteration 204, loss = 0.32680518\n",
            "Iteration 205, loss = 0.32703921\n",
            "Iteration 206, loss = 0.32915356\n",
            "Iteration 207, loss = 0.32826855\n",
            "Iteration 208, loss = 0.32602929\n",
            "Iteration 209, loss = 0.32467177\n",
            "Iteration 210, loss = 0.32585177\n",
            "Iteration 211, loss = 0.32501388\n",
            "Iteration 212, loss = 0.32602142\n",
            "Iteration 213, loss = 0.32517226\n",
            "Iteration 214, loss = 0.32468583\n",
            "Iteration 215, loss = 0.32719816\n",
            "Iteration 216, loss = 0.32313830\n",
            "Iteration 217, loss = 0.32245746\n",
            "Iteration 218, loss = 0.32240736\n",
            "Iteration 219, loss = 0.32239373\n",
            "Iteration 220, loss = 0.32376546\n",
            "Iteration 221, loss = 0.32117842\n",
            "Iteration 222, loss = 0.31989722\n",
            "Iteration 223, loss = 0.31874326\n",
            "Iteration 224, loss = 0.31931512\n",
            "Iteration 225, loss = 0.31970452\n",
            "Iteration 226, loss = 0.31814409\n",
            "Iteration 227, loss = 0.31828533\n",
            "Iteration 228, loss = 0.32004731\n",
            "Iteration 229, loss = 0.31752373\n",
            "Iteration 230, loss = 0.31762010\n",
            "Iteration 231, loss = 0.31757204\n",
            "Iteration 232, loss = 0.31661797\n",
            "Iteration 233, loss = 0.31659151\n",
            "Iteration 234, loss = 0.31595426\n",
            "Iteration 235, loss = 0.31581870\n",
            "Iteration 236, loss = 0.31868652\n",
            "Iteration 237, loss = 0.31461227\n",
            "Iteration 238, loss = 0.31575623\n",
            "Iteration 239, loss = 0.31407219\n",
            "Iteration 240, loss = 0.31419497\n",
            "Iteration 241, loss = 0.31837575\n",
            "Iteration 242, loss = 0.31638527\n",
            "Iteration 243, loss = 0.31406930\n",
            "Iteration 244, loss = 0.31376812\n",
            "Iteration 245, loss = 0.31202870\n",
            "Iteration 246, loss = 0.31164429\n",
            "Iteration 247, loss = 0.31414851\n",
            "Iteration 248, loss = 0.31306741\n",
            "Iteration 249, loss = 0.31369982\n",
            "Iteration 250, loss = 0.31295552\n",
            "Iteration 251, loss = 0.31269906\n",
            "Iteration 252, loss = 0.31545343\n",
            "Iteration 253, loss = 0.31528983\n",
            "Iteration 254, loss = 0.31228454\n",
            "Iteration 255, loss = 0.31314031\n",
            "Iteration 256, loss = 0.31610556\n",
            "Iteration 257, loss = 0.31205676\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.89471465\n",
            "Iteration 2, loss = 5.01169164\n",
            "Iteration 3, loss = 3.55078645\n",
            "Iteration 4, loss = 2.73931119\n",
            "Iteration 5, loss = 2.40028392\n",
            "Iteration 6, loss = 2.08014042\n",
            "Iteration 7, loss = 1.78445099\n",
            "Iteration 8, loss = 1.53538903\n",
            "Iteration 9, loss = 1.31139358\n",
            "Iteration 10, loss = 1.12137023\n",
            "Iteration 11, loss = 0.96334639\n",
            "Iteration 12, loss = 0.83930838\n",
            "Iteration 13, loss = 0.74412196\n",
            "Iteration 14, loss = 0.67885222\n",
            "Iteration 15, loss = 0.63585968\n",
            "Iteration 16, loss = 0.60448629\n",
            "Iteration 17, loss = 0.57985607\n",
            "Iteration 18, loss = 0.56372743\n",
            "Iteration 19, loss = 0.55038143\n",
            "Iteration 20, loss = 0.53960554\n",
            "Iteration 21, loss = 0.52937586\n",
            "Iteration 22, loss = 0.52114116\n",
            "Iteration 23, loss = 0.51377879\n",
            "Iteration 24, loss = 0.50766874\n",
            "Iteration 25, loss = 0.50121317\n",
            "Iteration 26, loss = 0.49577179\n",
            "Iteration 27, loss = 0.49224114\n",
            "Iteration 28, loss = 0.48661152\n",
            "Iteration 29, loss = 0.48277239\n",
            "Iteration 30, loss = 0.47994756\n",
            "Iteration 31, loss = 0.47664793\n",
            "Iteration 32, loss = 0.47271636\n",
            "Iteration 33, loss = 0.46961560\n",
            "Iteration 34, loss = 0.46635701\n",
            "Iteration 35, loss = 0.46518199\n",
            "Iteration 36, loss = 0.46186005\n",
            "Iteration 37, loss = 0.46007627\n",
            "Iteration 38, loss = 0.45747489\n",
            "Iteration 39, loss = 0.45726941\n",
            "Iteration 40, loss = 0.45663894\n",
            "Iteration 41, loss = 0.45297505\n",
            "Iteration 42, loss = 0.45013488\n",
            "Iteration 43, loss = 0.44804345\n",
            "Iteration 44, loss = 0.44794079\n",
            "Iteration 45, loss = 0.44549302\n",
            "Iteration 46, loss = 0.44373530\n",
            "Iteration 47, loss = 0.44322499\n",
            "Iteration 48, loss = 0.44132632\n",
            "Iteration 49, loss = 0.43902089\n",
            "Iteration 50, loss = 0.43791652\n",
            "Iteration 51, loss = 0.43722241\n",
            "Iteration 52, loss = 0.43590934\n",
            "Iteration 53, loss = 0.43357323\n",
            "Iteration 54, loss = 0.43247404\n",
            "Iteration 55, loss = 0.43150210\n",
            "Iteration 56, loss = 0.43001166\n",
            "Iteration 57, loss = 0.42953124\n",
            "Iteration 58, loss = 0.42842092\n",
            "Iteration 59, loss = 0.42816572\n",
            "Iteration 60, loss = 0.42900934\n",
            "Iteration 61, loss = 0.42594720\n",
            "Iteration 62, loss = 0.42328772\n",
            "Iteration 63, loss = 0.42225050\n",
            "Iteration 64, loss = 0.42130127\n",
            "Iteration 65, loss = 0.42024151\n",
            "Iteration 66, loss = 0.41946431\n",
            "Iteration 67, loss = 0.42000144\n",
            "Iteration 68, loss = 0.42132408\n",
            "Iteration 69, loss = 0.41892850\n",
            "Iteration 70, loss = 0.42073790\n",
            "Iteration 71, loss = 0.41605921\n",
            "Iteration 72, loss = 0.41502477\n",
            "Iteration 73, loss = 0.41380698\n",
            "Iteration 74, loss = 0.41317107\n",
            "Iteration 75, loss = 0.41057311\n",
            "Iteration 76, loss = 0.40920930\n",
            "Iteration 77, loss = 0.40833675\n",
            "Iteration 78, loss = 0.40728119\n",
            "Iteration 79, loss = 0.40670683\n",
            "Iteration 80, loss = 0.40659202\n",
            "Iteration 81, loss = 0.40684543\n",
            "Iteration 82, loss = 0.40656285\n",
            "Iteration 83, loss = 0.40346176\n",
            "Iteration 84, loss = 0.40236888\n",
            "Iteration 85, loss = 0.40292959\n",
            "Iteration 86, loss = 0.40271753\n",
            "Iteration 87, loss = 0.39951078\n",
            "Iteration 88, loss = 0.40072354\n",
            "Iteration 89, loss = 0.39804689\n",
            "Iteration 90, loss = 0.39733207\n",
            "Iteration 91, loss = 0.39874146\n",
            "Iteration 92, loss = 0.39693981\n",
            "Iteration 93, loss = 0.39621363\n",
            "Iteration 94, loss = 0.39478126\n",
            "Iteration 95, loss = 0.39489442\n",
            "Iteration 96, loss = 0.39375418\n",
            "Iteration 97, loss = 0.39107428\n",
            "Iteration 98, loss = 0.39168969\n",
            "Iteration 99, loss = 0.39153904\n",
            "Iteration 100, loss = 0.38927630\n",
            "Iteration 101, loss = 0.39024526\n",
            "Iteration 102, loss = 0.38850039\n",
            "Iteration 103, loss = 0.38881412\n",
            "Iteration 104, loss = 0.38510110\n",
            "Iteration 105, loss = 0.38730155\n",
            "Iteration 106, loss = 0.38597378\n",
            "Iteration 107, loss = 0.38544157\n",
            "Iteration 108, loss = 0.38297132\n",
            "Iteration 109, loss = 0.38202604\n",
            "Iteration 110, loss = 0.38184962\n",
            "Iteration 111, loss = 0.38133254\n",
            "Iteration 112, loss = 0.38092076\n",
            "Iteration 113, loss = 0.38001078\n",
            "Iteration 114, loss = 0.37857468\n",
            "Iteration 115, loss = 0.37751736\n",
            "Iteration 116, loss = 0.37705986\n",
            "Iteration 117, loss = 0.37726496\n",
            "Iteration 118, loss = 0.37655086\n",
            "Iteration 119, loss = 0.37494470\n",
            "Iteration 120, loss = 0.37408998\n",
            "Iteration 121, loss = 0.37638909\n",
            "Iteration 122, loss = 0.37952259\n",
            "Iteration 123, loss = 0.37262399\n",
            "Iteration 124, loss = 0.37206740\n",
            "Iteration 125, loss = 0.37006398\n",
            "Iteration 126, loss = 0.36950318\n",
            "Iteration 127, loss = 0.36895455\n",
            "Iteration 128, loss = 0.37058114\n",
            "Iteration 129, loss = 0.37169595\n",
            "Iteration 130, loss = 0.36716127\n",
            "Iteration 131, loss = 0.36660879\n",
            "Iteration 132, loss = 0.36565935\n",
            "Iteration 133, loss = 0.36557930\n",
            "Iteration 134, loss = 0.36513274\n",
            "Iteration 135, loss = 0.36386031\n",
            "Iteration 136, loss = 0.36386616\n",
            "Iteration 137, loss = 0.36508086\n",
            "Iteration 138, loss = 0.36474835\n",
            "Iteration 139, loss = 0.36119745\n",
            "Iteration 140, loss = 0.36128679\n",
            "Iteration 141, loss = 0.35994116\n",
            "Iteration 142, loss = 0.35979246\n",
            "Iteration 143, loss = 0.36000540\n",
            "Iteration 144, loss = 0.35801238\n",
            "Iteration 145, loss = 0.35767194\n",
            "Iteration 146, loss = 0.35706886\n",
            "Iteration 147, loss = 0.35609308\n",
            "Iteration 148, loss = 0.35668144\n",
            "Iteration 149, loss = 0.35637461\n",
            "Iteration 150, loss = 0.35491372\n",
            "Iteration 151, loss = 0.35400976\n",
            "Iteration 152, loss = 0.35361899\n",
            "Iteration 153, loss = 0.35292595\n",
            "Iteration 154, loss = 0.35333413\n",
            "Iteration 155, loss = 0.35257078\n",
            "Iteration 156, loss = 0.35172292\n",
            "Iteration 157, loss = 0.35317534\n",
            "Iteration 158, loss = 0.35061348\n",
            "Iteration 159, loss = 0.35059476\n",
            "Iteration 160, loss = 0.35580838\n",
            "Iteration 161, loss = 0.35324211\n",
            "Iteration 162, loss = 0.34819532\n",
            "Iteration 163, loss = 0.34740531\n",
            "Iteration 164, loss = 0.34835755\n",
            "Iteration 165, loss = 0.34773586\n",
            "Iteration 166, loss = 0.34621826\n",
            "Iteration 167, loss = 0.34497540\n",
            "Iteration 168, loss = 0.34482579\n",
            "Iteration 169, loss = 0.34548138\n",
            "Iteration 170, loss = 0.34573308\n",
            "Iteration 171, loss = 0.34249634\n",
            "Iteration 172, loss = 0.34291864\n",
            "Iteration 173, loss = 0.34216489\n",
            "Iteration 174, loss = 0.34159344\n",
            "Iteration 175, loss = 0.34175322\n",
            "Iteration 176, loss = 0.34149055\n",
            "Iteration 177, loss = 0.34158354\n",
            "Iteration 178, loss = 0.33944984\n",
            "Iteration 179, loss = 0.34072416\n",
            "Iteration 180, loss = 0.33768622\n",
            "Iteration 181, loss = 0.33928853\n",
            "Iteration 182, loss = 0.33783410\n",
            "Iteration 183, loss = 0.33684974\n",
            "Iteration 184, loss = 0.33620262\n",
            "Iteration 185, loss = 0.33702983\n",
            "Iteration 186, loss = 0.33490955\n",
            "Iteration 187, loss = 0.33634443\n",
            "Iteration 188, loss = 0.33925256\n",
            "Iteration 189, loss = 0.33439603\n",
            "Iteration 190, loss = 0.33339316\n",
            "Iteration 191, loss = 0.33300817\n",
            "Iteration 192, loss = 0.33313104\n",
            "Iteration 193, loss = 0.33237354\n",
            "Iteration 194, loss = 0.33364301\n",
            "Iteration 195, loss = 0.33083666\n",
            "Iteration 196, loss = 0.33013986\n",
            "Iteration 197, loss = 0.32947897\n",
            "Iteration 198, loss = 0.33182083\n",
            "Iteration 199, loss = 0.32882460\n",
            "Iteration 200, loss = 0.32812790\n",
            "Iteration 201, loss = 0.32928583\n",
            "Iteration 202, loss = 0.33119596\n",
            "Iteration 203, loss = 0.32876295\n",
            "Iteration 204, loss = 0.32759118\n",
            "Iteration 205, loss = 0.32719913\n",
            "Iteration 206, loss = 0.32607301\n",
            "Iteration 207, loss = 0.32584364\n",
            "Iteration 208, loss = 0.32746810\n",
            "Iteration 209, loss = 0.32425574\n",
            "Iteration 210, loss = 0.32394575\n",
            "Iteration 211, loss = 0.32384081\n",
            "Iteration 212, loss = 0.32387501\n",
            "Iteration 213, loss = 0.32386179\n",
            "Iteration 214, loss = 0.32413899\n",
            "Iteration 215, loss = 0.32278128\n",
            "Iteration 216, loss = 0.32627303\n",
            "Iteration 217, loss = 0.32139936\n",
            "Iteration 218, loss = 0.32241452\n",
            "Iteration 219, loss = 0.32513242\n",
            "Iteration 220, loss = 0.32307885\n",
            "Iteration 221, loss = 0.32159673\n",
            "Iteration 222, loss = 0.32376914\n",
            "Iteration 223, loss = 0.32079592\n",
            "Iteration 224, loss = 0.31975750\n",
            "Iteration 225, loss = 0.31886057\n",
            "Iteration 226, loss = 0.31815281\n",
            "Iteration 227, loss = 0.31782227\n",
            "Iteration 228, loss = 0.31734617\n",
            "Iteration 229, loss = 0.31627786\n",
            "Iteration 230, loss = 0.31643126\n",
            "Iteration 231, loss = 0.31847053\n",
            "Iteration 232, loss = 0.31667198\n",
            "Iteration 233, loss = 0.31526357\n",
            "Iteration 234, loss = 0.31554323\n",
            "Iteration 235, loss = 0.31578863\n",
            "Iteration 236, loss = 0.31415908\n",
            "Iteration 237, loss = 0.31362796\n",
            "Iteration 238, loss = 0.31378740\n",
            "Iteration 239, loss = 0.31333403\n",
            "Iteration 240, loss = 0.31472447\n",
            "Iteration 241, loss = 0.31500211\n",
            "Iteration 242, loss = 0.31606271\n",
            "Iteration 243, loss = 0.31531428\n",
            "Iteration 244, loss = 0.31124660\n",
            "Iteration 245, loss = 0.31048026\n",
            "Iteration 246, loss = 0.31025587\n",
            "Iteration 247, loss = 0.31204051\n",
            "Iteration 248, loss = 0.30981413\n",
            "Iteration 249, loss = 0.30989098\n",
            "Iteration 250, loss = 0.31023215\n",
            "Iteration 251, loss = 0.31012397\n",
            "Iteration 252, loss = 0.30898518\n",
            "Iteration 253, loss = 0.30942021\n",
            "Iteration 254, loss = 0.30908603\n",
            "Iteration 255, loss = 0.31299800\n",
            "Iteration 256, loss = 0.31025140\n",
            "Iteration 257, loss = 0.30731627\n",
            "Iteration 258, loss = 0.30841891\n",
            "Iteration 259, loss = 0.30731036\n",
            "Iteration 260, loss = 0.30680605\n",
            "Iteration 261, loss = 0.30672803\n",
            "Iteration 262, loss = 0.30528194\n",
            "Iteration 263, loss = 0.30633588\n",
            "Iteration 264, loss = 0.30749604\n",
            "Iteration 265, loss = 0.30497193\n",
            "Iteration 266, loss = 0.30443213\n",
            "Iteration 267, loss = 0.30596968\n",
            "Iteration 268, loss = 0.30368294\n",
            "Iteration 269, loss = 0.30380541\n",
            "Iteration 270, loss = 0.30491199\n",
            "Iteration 271, loss = 0.30601389\n",
            "Iteration 272, loss = 0.30508883\n",
            "Iteration 273, loss = 0.30304444\n",
            "Iteration 274, loss = 0.30470287\n",
            "Iteration 275, loss = 0.30314737\n",
            "Iteration 276, loss = 0.30627122\n",
            "Iteration 277, loss = 0.30115267\n",
            "Iteration 278, loss = 0.30471929\n",
            "Iteration 279, loss = 0.30204828\n",
            "Iteration 280, loss = 0.30080416\n",
            "Iteration 281, loss = 0.30378060\n",
            "Iteration 282, loss = 0.29984463\n",
            "Iteration 283, loss = 0.30044612\n",
            "Iteration 284, loss = 0.30032246\n",
            "Iteration 285, loss = 0.29999893\n",
            "Iteration 286, loss = 0.29956498\n",
            "Iteration 287, loss = 0.30001971\n",
            "Iteration 288, loss = 0.30032845\n",
            "Iteration 289, loss = 0.30041655\n",
            "Iteration 290, loss = 0.29930151\n",
            "Iteration 291, loss = 0.29830817\n",
            "Iteration 292, loss = 0.29845301\n",
            "Iteration 293, loss = 0.30379320\n",
            "Iteration 294, loss = 0.29786470\n",
            "Iteration 295, loss = 0.29820801\n",
            "Iteration 296, loss = 0.29636595\n",
            "Iteration 297, loss = 0.29622944\n",
            "Iteration 298, loss = 0.29612434\n",
            "Iteration 299, loss = 0.29569288\n",
            "Iteration 300, loss = 0.29687709\n",
            "Iteration 301, loss = 0.29859029\n",
            "Iteration 302, loss = 0.29991943\n",
            "Iteration 303, loss = 0.29814874\n",
            "Iteration 304, loss = 0.30180285\n",
            "Iteration 305, loss = 0.29437967\n",
            "Iteration 306, loss = 0.29454514\n",
            "Iteration 307, loss = 0.29471946\n",
            "Iteration 308, loss = 0.29686798\n",
            "Iteration 309, loss = 0.29298163\n",
            "Iteration 310, loss = 0.29298022\n",
            "Iteration 311, loss = 0.29498110\n",
            "Iteration 312, loss = 0.29415850\n",
            "Iteration 313, loss = 0.29412947\n",
            "Iteration 314, loss = 0.29505741\n",
            "Iteration 315, loss = 0.29185801\n",
            "Iteration 316, loss = 0.29275502\n",
            "Iteration 317, loss = 0.29159042\n",
            "Iteration 318, loss = 0.29325590\n",
            "Iteration 319, loss = 0.29209225\n",
            "Iteration 320, loss = 0.29185461\n",
            "Iteration 321, loss = 0.29265948\n",
            "Iteration 322, loss = 0.29062907\n",
            "Iteration 323, loss = 0.29113184\n",
            "Iteration 324, loss = 0.29072594\n",
            "Iteration 325, loss = 0.29012532\n",
            "Iteration 326, loss = 0.29158501\n",
            "Iteration 327, loss = 0.29042426\n",
            "Iteration 328, loss = 0.29268285\n",
            "Iteration 329, loss = 0.28935352\n",
            "Iteration 330, loss = 0.29245020\n",
            "Iteration 331, loss = 0.28967044\n",
            "Iteration 332, loss = 0.28980356\n",
            "Iteration 333, loss = 0.29808491\n",
            "Iteration 334, loss = 0.29289054\n",
            "Iteration 335, loss = 0.29427082\n",
            "Iteration 336, loss = 0.29032207\n",
            "Iteration 337, loss = 0.28858505\n",
            "Iteration 338, loss = 0.28739836\n",
            "Iteration 339, loss = 0.28689747\n",
            "Iteration 340, loss = 0.28812358\n",
            "Iteration 341, loss = 0.28777760\n",
            "Iteration 342, loss = 0.28501620\n",
            "Iteration 343, loss = 0.28566899\n",
            "Iteration 344, loss = 0.28733549\n",
            "Iteration 345, loss = 0.28496571\n",
            "Iteration 346, loss = 0.28436374\n",
            "Iteration 347, loss = 0.28448133\n",
            "Iteration 348, loss = 0.28477817\n",
            "Iteration 349, loss = 0.28334779\n",
            "Iteration 350, loss = 0.28441534\n",
            "Iteration 351, loss = 0.28392523\n",
            "Iteration 352, loss = 0.28373391\n",
            "Iteration 353, loss = 0.28263225\n",
            "Iteration 354, loss = 0.28287372\n",
            "Iteration 355, loss = 0.28312168\n",
            "Iteration 356, loss = 0.28539716\n",
            "Iteration 357, loss = 0.28551411\n",
            "Iteration 358, loss = 0.28610351\n",
            "Iteration 359, loss = 0.28485526\n",
            "Iteration 360, loss = 0.28346215\n",
            "Iteration 361, loss = 0.28063757\n",
            "Iteration 362, loss = 0.28072577\n",
            "Iteration 363, loss = 0.28157418\n",
            "Iteration 364, loss = 0.28290318\n",
            "Iteration 365, loss = 0.28030085\n",
            "Iteration 366, loss = 0.28004078\n",
            "Iteration 367, loss = 0.27971894\n",
            "Iteration 368, loss = 0.27961834\n",
            "Iteration 369, loss = 0.27836244\n",
            "Iteration 370, loss = 0.28169364\n",
            "Iteration 371, loss = 0.28175639\n",
            "Iteration 372, loss = 0.27870663\n",
            "Iteration 373, loss = 0.27917336\n",
            "Iteration 374, loss = 0.27810874\n",
            "Iteration 375, loss = 0.27886999\n",
            "Iteration 376, loss = 0.27774384\n",
            "Iteration 377, loss = 0.27874391\n",
            "Iteration 378, loss = 0.27777042\n",
            "Iteration 379, loss = 0.27724570\n",
            "Iteration 380, loss = 0.27727858\n",
            "Iteration 381, loss = 0.27914958\n",
            "Iteration 382, loss = 0.27933129\n",
            "Iteration 383, loss = 0.27809733\n",
            "Iteration 384, loss = 0.28129588\n",
            "Iteration 385, loss = 0.27750228\n",
            "Iteration 386, loss = 0.27730735\n",
            "Iteration 387, loss = 0.27644963\n",
            "Iteration 388, loss = 0.27728497\n",
            "Iteration 389, loss = 0.27683578\n",
            "Iteration 390, loss = 0.27650999\n",
            "Iteration 391, loss = 0.27727389\n",
            "Iteration 392, loss = 0.27894087\n",
            "Iteration 393, loss = 0.28057124\n",
            "Iteration 394, loss = 0.27870289\n",
            "Iteration 395, loss = 0.28010138\n",
            "Iteration 396, loss = 0.27694520\n",
            "Iteration 397, loss = 0.27695447\n",
            "Iteration 398, loss = 0.27598444\n",
            "Iteration 399, loss = 0.27777007\n",
            "Iteration 400, loss = 0.27663473\n",
            "Iteration 401, loss = 0.27671936\n",
            "Iteration 402, loss = 0.28091717\n",
            "Iteration 403, loss = 0.27711463\n",
            "Iteration 404, loss = 0.27902449\n",
            "Iteration 405, loss = 0.27723650\n",
            "Iteration 406, loss = 0.27500439\n",
            "Iteration 407, loss = 0.27480608\n",
            "Iteration 408, loss = 0.27736531\n",
            "Iteration 409, loss = 0.27570485\n",
            "Iteration 410, loss = 0.27458362\n",
            "Iteration 411, loss = 0.27465430\n",
            "Iteration 412, loss = 0.27478866\n",
            "Iteration 413, loss = 0.27754424\n",
            "Iteration 414, loss = 0.27358882\n",
            "Iteration 415, loss = 0.27436005\n",
            "Iteration 416, loss = 0.27561581\n",
            "Iteration 417, loss = 0.27425592\n",
            "Iteration 418, loss = 0.27370591\n",
            "Iteration 419, loss = 0.27427527\n",
            "Iteration 420, loss = 0.27366715\n",
            "Iteration 421, loss = 0.27404023\n",
            "Iteration 422, loss = 0.27378731\n",
            "Iteration 423, loss = 0.27462810\n",
            "Iteration 424, loss = 0.27611178\n",
            "Iteration 425, loss = 0.27655059\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(acc)):\n",
        "  print('Asset0'+format(i)+' Accuracy :'+format(acc[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPramUhmyzss",
        "outputId": "c22ab344-42f9-4700-bb99-4c917d783da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset00 Accuracy :0.8349056603773585\n",
            "Asset01 Accuracy :0.75\n",
            "Asset02 Accuracy :0.8443396226415094\n",
            "Asset03 Accuracy :0.9198113207547169\n",
            "Asset04 Accuracy :0.9858490566037735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mgR5MMAhD_rH",
        "outputId": "4502cd0f-05d3-4309-b193-2dec05d6c002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycaret\n",
            "  Downloading pycaret-2.3.6-py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml<6.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.13)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.3.5)\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.5)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 43.9 MB/s \n",
            "\u001b[?25hCollecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 47.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.24.0-py3-none-any.whl (16.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.5 MB 189 kB/s \n",
            "\u001b[?25hCollecting kmodes>=0.10.1\n",
            "  Downloading kmodes-0.11.1-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.6.5)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)\n",
            "Collecting pyod\n",
            "  Downloading pyod-0.9.7.tar.gz (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.2)\n",
            "Collecting imbalanced-learn==0.7.0\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 54.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting yellowbrick>=1.0.1\n",
            "  Downloading yellowbrick-1.4-py3-none-any.whl (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Collecting mlxtend>=0.17.0\n",
            "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 58.6 MB/s \n",
            "\u001b[?25hCollecting pandas-profiling>=2.8.0\n",
            "  Downloading pandas_profiling-3.1.0-py2.py3-none-any.whl (261 kB)\n",
            "\u001b[K     |████████████████████████████████| 261 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn==0.7.0->pycaret) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->pycaret) (3.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (57.4.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret) (5.2.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (3.5.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret) (0.37.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (0.11.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.9.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (4.11.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Collecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting tangled-up-in-unicode==0.1.0\n",
            "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 42.8 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0.0\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 55.7 MB/s \n",
            "\u001b[?25hCollecting htmlmin>=0.1.12\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Collecting multimethod>=1.4\n",
            "  Downloading multimethod-1.7-py3-none-any.whl (9.5 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "\u001b[K     |████████████████████████████████| 303 kB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (4.62.3)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.3)\n",
            "Requirement already satisfied: markupsafe~=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
            "Collecting visions[type_image_path]==0.7.4\n",
            "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 10.9 MB/s \n",
            "\u001b[?25hCollecting phik>=0.11.1\n",
            "  Downloading phik-0.12.0-cp37-cp37m-manylinux2010_x86_64.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (2.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (7.1.2)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 59.6 MB/s \n",
            "\u001b[?25hCollecting scipy<=1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret) (8.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.9.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.13.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.0)\n",
            "Collecting yellowbrick>=1.0.1\n",
            "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.13.3\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret) (1.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4.2)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.17.3)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.7-py3-none-any.whl (17 kB)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 54.6 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (21.3)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.31)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (4.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.13.1)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 42.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret) (0.5.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin, imagehash, databricks-cli, pyLDAvis, pyod, umap-learn, pynndescent\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=2541dd8c0409601e12b6fd399e3e64ea628db376a461023ef5c132cc2eef89ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=4aa9d1525e414fa4f529c8d9c07758120d4f174f8698d14c7c5ff7bd4f8f592a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.4-py3-none-any.whl size=106877 sha256=baeb5f2fbf44a5fe841575e280879c0ac378496762a77a3db911319901a6d0f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/a1/6d/fa1d22ea25ed8593887437fe1c7e00f6ef307fc240ccd4dc5c\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135617 sha256=64808e3414f022f4ecdb8e75193d920fc6c8db75fc7e5c318e99ae75b27b166f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/b1/9b/560ac1931796b7303f7b517b949d2d31a4fbc512aad3b9f284\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.7-py3-none-any.whl size=136279 sha256=d8304c06f8b097337f46e4865db372fc73c3f36572f2a8a4c700bfee181b0f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/14/ae/60cbb36511e59bc12f8f0883805f586db3b315972b54865d33\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82708 sha256=db8be8ce529d915ef60731f0b8a1d057851e93eddd69c2249ddecfe1905b3453\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=73d88c03d283a4461413233d28216126a3374bfef169ef305d2c9d5eebb13a20\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "Successfully built htmlmin imagehash databricks-cli pyLDAvis pyod umap-learn pynndescent\n",
            "Installing collected packages: numpy, tangled-up-in-unicode, smmap, scipy, multimethod, joblib, websocket-client, visions, scikit-learn, requests, Mako, imagehash, gitdb, querystring-parser, pyyaml, pynndescent, pydantic, prometheus-flask-exporter, phik, htmlmin, gunicorn, gitpython, funcy, docker, databricks-cli, alembic, yellowbrick, umap-learn, scikit-plot, pyod, pyLDAvis, pandas-profiling, mlxtend, mlflow, lightgbm, kmodes, imbalanced-learn, Boruta, pycaret\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pandas-profiling\n",
            "    Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Attempting uninstall: mlxtend\n",
            "    Found existing installation: mlxtend 0.14.0\n",
            "    Uninstalling mlxtend-0.14.0:\n",
            "      Successfully uninstalled mlxtend-0.14.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.8.1\n",
            "    Uninstalling imbalanced-learn-0.8.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Boruta-0.3 Mako-1.1.6 alembic-1.7.6 databricks-cli-0.16.4 docker-5.0.3 funcy-1.17 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.1 imbalanced-learn-0.7.0 joblib-1.0.1 kmodes-0.11.1 lightgbm-3.3.2 mlflow-1.24.0 mlxtend-0.19.0 multimethod-1.7 numpy-1.19.5 pandas-profiling-3.1.0 phik-0.12.0 prometheus-flask-exporter-0.18.7 pyLDAvis-3.2.2 pycaret-2.3.6 pydantic-1.9.0 pynndescent-0.5.6 pyod-0.9.7 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.27.1 scikit-learn-0.23.2 scikit-plot-0.3.7 scipy-1.5.4 smmap-5.0.0 tangled-up-in-unicode-0.1.0 umap-learn-0.5.2 visions-0.7.4 websocket-client-1.3.1 yellowbrick-1.3.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "numpy",
                  "requests",
                  "scipy",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAHh7TxFH3Sr",
        "outputId": "81b4683b-f813-4d99-8073-3453f389af34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvZYVRtlPCDb",
        "outputId": "104653aa-a795-4d73-818f-684645a92ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 564 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.5.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.23.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.40.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf5 = setup(result05, target = 'Long')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "69de51ab751a4cc9a94ee6e14579c7c0",
            "0dfe5bca70644cdfa364bc6e9591a87e",
            "899664fdc09e4d50b89e6ef79a842e59",
            "6a1bb85ffb6f411e9b4e47b1ae13e793",
            "d83c22aa72d74c4db10ef506f47ea46a",
            "66825b4620354386b816592f935bbbbd"
          ]
        },
        "id": "xmE62UdsH7q_",
        "outputId": "ce468e6e-90f3-48c4-af31-0a94df264808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9528e861-d648-4f2a-b2bd-45cbaf0f7a43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>5848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>0.0: 0, 1.0: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(2111, 7)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(1477, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(634, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>0805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9528e861-d648-4f2a-b2bd-45cbaf0f7a43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9528e861-d648-4f2a-b2bd-45cbaf0f7a43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9528e861-d648-4f2a-b2bd-45cbaf0f7a43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id              5848\n",
              "1                                   Target              Long\n",
              "2                              Target Type            Binary\n",
              "3                            Label Encoded    0.0: 0, 1.0: 1\n",
              "4                            Original Data         (2111, 7)\n",
              "5                           Missing Values             False\n",
              "6                         Numeric Features                 6\n",
              "7                     Categorical Features                 0\n",
              "8                         Ordinal Features             False\n",
              "9                High Cardinality Features             False\n",
              "10                 High Cardinality Method              None\n",
              "11                   Transformed Train Set         (1477, 5)\n",
              "12                    Transformed Test Set          (634, 5)\n",
              "13                      Shuffle Train-Test              True\n",
              "14                     Stratify Train-Test             False\n",
              "15                          Fold Generator   StratifiedKFold\n",
              "16                             Fold Number                10\n",
              "17                                CPU Jobs                -1\n",
              "18                                 Use GPU             False\n",
              "19                          Log Experiment             False\n",
              "20                         Experiment Name  clf-default-name\n",
              "21                                     USI              0805\n",
              "22                         Imputation Type            simple\n",
              "23          Iterative Imputation Iteration              None\n",
              "24                         Numeric Imputer              mean\n",
              "25      Iterative Imputation Numeric Model              None\n",
              "26                     Categorical Imputer          constant\n",
              "27  Iterative Imputation Categorical Model              None\n",
              "28           Unknown Categoricals Handling    least_frequent\n",
              "29                               Normalize             False\n",
              "30                        Normalize Method              None\n",
              "31                          Transformation             False\n",
              "32                   Transformation Method              None\n",
              "33                                     PCA             False\n",
              "34                              PCA Method              None\n",
              "35                          PCA Components              None\n",
              "36                     Ignore Low Variance             False\n",
              "37                     Combine Rare Levels             False\n",
              "38                    Rare Level Threshold              None\n",
              "39                         Numeric Binning             False\n",
              "40                         Remove Outliers             False\n",
              "41                      Outliers Threshold              None\n",
              "42                Remove Multicollinearity             False\n",
              "43             Multicollinearity Threshold              None\n",
              "44             Remove Perfect Collinearity              True\n",
              "45                              Clustering             False\n",
              "46                    Clustering Iteration              None\n",
              "47                     Polynomial Features             False\n",
              "48                       Polynomial Degree              None\n",
              "49                    Trignometry Features             False\n",
              "50                    Polynomial Threshold              None\n",
              "51                          Group Features             False\n",
              "52                       Feature Selection             False\n",
              "53                Feature Selection Method           classic\n",
              "54            Features Selection Threshold              None\n",
              "55                     Feature Interaction             False\n",
              "56                           Feature Ratio             False\n",
              "57                   Interaction Threshold              None\n",
              "58                           Fix Imbalance             False\n",
              "59                    Fix Imbalance Method             SMOTE"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ast5 = compare_models(sort = 'Accuracy', fold = 5, n_select = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "6bafed17c4fd4f65b09aa952ce4be872",
            "fe3497849a2a4445a67385b85981ce0f",
            "df801dbb519d4864912d5cfc0ffd67a9"
          ]
        },
        "id": "ldKl3BCfMcdn",
        "outputId": "c3dcf111-9f75-4046-df7f-6b69b99866be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3247b703-d352-4bad-ac76-ff026deb495f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.9147</td>\n",
              "      <td>0.9677</td>\n",
              "      <td>0.9127</td>\n",
              "      <td>0.8622</td>\n",
              "      <td>0.8862</td>\n",
              "      <td>0.8180</td>\n",
              "      <td>0.8197</td>\n",
              "      <td>0.570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.9133</td>\n",
              "      <td>0.9689</td>\n",
              "      <td>0.9332</td>\n",
              "      <td>0.8457</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.8170</td>\n",
              "      <td>0.8200</td>\n",
              "      <td>0.676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.9100</td>\n",
              "      <td>0.9677</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8460</td>\n",
              "      <td>0.8818</td>\n",
              "      <td>0.8093</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>0.234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.9073</td>\n",
              "      <td>0.9692</td>\n",
              "      <td>0.9091</td>\n",
              "      <td>0.8488</td>\n",
              "      <td>0.8776</td>\n",
              "      <td>0.8031</td>\n",
              "      <td>0.8047</td>\n",
              "      <td>0.090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.9012</td>\n",
              "      <td>0.9645</td>\n",
              "      <td>0.9054</td>\n",
              "      <td>0.8377</td>\n",
              "      <td>0.8699</td>\n",
              "      <td>0.7904</td>\n",
              "      <td>0.7924</td>\n",
              "      <td>0.144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>0.9520</td>\n",
              "      <td>0.8367</td>\n",
              "      <td>0.8422</td>\n",
              "      <td>0.8381</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.8788</td>\n",
              "      <td>0.8687</td>\n",
              "      <td>0.8312</td>\n",
              "      <td>0.8359</td>\n",
              "      <td>0.8335</td>\n",
              "      <td>0.7382</td>\n",
              "      <td>0.7383</td>\n",
              "      <td>0.028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8774</td>\n",
              "      <td>0.9543</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8372</td>\n",
              "      <td>0.8303</td>\n",
              "      <td>0.7345</td>\n",
              "      <td>0.7357</td>\n",
              "      <td>0.096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.8734</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8089</td>\n",
              "      <td>0.8384</td>\n",
              "      <td>0.8224</td>\n",
              "      <td>0.7242</td>\n",
              "      <td>0.7255</td>\n",
              "      <td>0.030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8713</td>\n",
              "      <td>0.9521</td>\n",
              "      <td>0.8107</td>\n",
              "      <td>0.8321</td>\n",
              "      <td>0.8204</td>\n",
              "      <td>0.7203</td>\n",
              "      <td>0.7214</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8551</td>\n",
              "      <td>0.9169</td>\n",
              "      <td>0.7866</td>\n",
              "      <td>0.8108</td>\n",
              "      <td>0.7980</td>\n",
              "      <td>0.6851</td>\n",
              "      <td>0.6858</td>\n",
              "      <td>0.212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8287</td>\n",
              "      <td>0.9113</td>\n",
              "      <td>0.7829</td>\n",
              "      <td>0.7567</td>\n",
              "      <td>0.7690</td>\n",
              "      <td>0.6330</td>\n",
              "      <td>0.6339</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7549</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3841</td>\n",
              "      <td>0.9036</td>\n",
              "      <td>0.4769</td>\n",
              "      <td>0.3816</td>\n",
              "      <td>0.4471</td>\n",
              "      <td>0.036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.6351</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3247b703-d352-4bad-ac76-ff026deb495f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3247b703-d352-4bad-ac76-ff026deb495f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3247b703-d352-4bad-ac76-ff026deb495f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "et                 Extra Trees Classifier    0.9147  0.9677  0.9127  0.8622   \n",
              "rf               Random Forest Classifier    0.9133  0.9689  0.9332  0.8457   \n",
              "gbc          Gradient Boosting Classifier    0.9100  0.9677  0.9220  0.8460   \n",
              "lightgbm  Light Gradient Boosting Machine    0.9073  0.9692  0.9091  0.8488   \n",
              "ada                  Ada Boost Classifier    0.9012  0.9645  0.9054  0.8377   \n",
              "qda       Quadratic Discriminant Analysis    0.8829  0.9520  0.8367  0.8422   \n",
              "dt               Decision Tree Classifier    0.8788  0.8687  0.8312  0.8359   \n",
              "lr                    Logistic Regression    0.8774  0.9543  0.8255  0.8372   \n",
              "ridge                    Ridge Classifier    0.8734  0.0000  0.8089  0.8384   \n",
              "lda          Linear Discriminant Analysis    0.8713  0.9521  0.8107  0.8321   \n",
              "knn                K Neighbors Classifier    0.8551  0.9169  0.7866  0.8108   \n",
              "nb                            Naive Bayes    0.8287  0.9113  0.7829  0.7567   \n",
              "svm                   SVM - Linear Kernel    0.7549  0.0000  0.3841  0.9036   \n",
              "dummy                    Dummy Classifier    0.6351  0.5000  0.0000  0.0000   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "et        0.8862  0.8180  0.8197     0.570  \n",
              "rf        0.8870  0.8170  0.8200     0.676  \n",
              "gbc       0.8818  0.8093  0.8120     0.234  \n",
              "lightgbm  0.8776  0.8031  0.8047     0.090  \n",
              "ada       0.8699  0.7904  0.7924     0.144  \n",
              "qda       0.8381  0.7464  0.7480     0.018  \n",
              "dt        0.8335  0.7382  0.7383     0.028  \n",
              "lr        0.8303  0.7345  0.7357     0.096  \n",
              "ridge     0.8224  0.7242  0.7255     0.030  \n",
              "lda       0.8204  0.7203  0.7214     0.020  \n",
              "knn       0.7980  0.6851  0.6858     0.212  \n",
              "nb        0.7690  0.6330  0.6339     0.032  \n",
              "svm       0.4769  0.3816  0.4471     0.036  \n",
              "dummy     0.0000  0.0000  0.0000     0.018  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "et_ast5_model = create_model('et')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425,
          "referenced_widgets": [
            "bfb910b0aced48b4beac1dcfb8678a44",
            "7631a6bf2ba44efabb5fa82f530a9d7a",
            "3c6263428bd240278b4b47cf1baea28c"
          ]
        },
        "id": "zWI0TYNqM8d0",
        "outputId": "25a242d9-53ce-4326-987e-099119bd62c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e82c49ba-f14f-45a5-8f16-400d35faa06a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.8919</td>\n",
              "      <td>0.9709</td>\n",
              "      <td>0.9074</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8596</td>\n",
              "      <td>0.7721</td>\n",
              "      <td>0.7750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9189</td>\n",
              "      <td>0.9717</td>\n",
              "      <td>0.9259</td>\n",
              "      <td>0.8621</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8278</td>\n",
              "      <td>0.8291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9459</td>\n",
              "      <td>0.9742</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>0.9107</td>\n",
              "      <td>0.9273</td>\n",
              "      <td>0.8843</td>\n",
              "      <td>0.8847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.8851</td>\n",
              "      <td>0.9537</td>\n",
              "      <td>0.9259</td>\n",
              "      <td>0.7937</td>\n",
              "      <td>0.8547</td>\n",
              "      <td>0.7607</td>\n",
              "      <td>0.7668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9527</td>\n",
              "      <td>0.9905</td>\n",
              "      <td>0.9630</td>\n",
              "      <td>0.9123</td>\n",
              "      <td>0.9369</td>\n",
              "      <td>0.8991</td>\n",
              "      <td>0.9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.9189</td>\n",
              "      <td>0.9753</td>\n",
              "      <td>0.9259</td>\n",
              "      <td>0.8621</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8278</td>\n",
              "      <td>0.8291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.8784</td>\n",
              "      <td>0.9566</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8421</td>\n",
              "      <td>0.7436</td>\n",
              "      <td>0.7464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.9048</td>\n",
              "      <td>0.9621</td>\n",
              "      <td>0.8519</td>\n",
              "      <td>0.8846</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.7935</td>\n",
              "      <td>0.7938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9116</td>\n",
              "      <td>0.9694</td>\n",
              "      <td>0.8704</td>\n",
              "      <td>0.8868</td>\n",
              "      <td>0.8785</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.8091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.8980</td>\n",
              "      <td>0.9669</td>\n",
              "      <td>0.9057</td>\n",
              "      <td>0.8276</td>\n",
              "      <td>0.8649</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9106</td>\n",
              "      <td>0.9691</td>\n",
              "      <td>0.9109</td>\n",
              "      <td>0.8556</td>\n",
              "      <td>0.8818</td>\n",
              "      <td>0.8101</td>\n",
              "      <td>0.8119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0099</td>\n",
              "      <td>0.0319</td>\n",
              "      <td>0.0417</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0483</td>\n",
              "      <td>0.0473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e82c49ba-f14f-45a5-8f16-400d35faa06a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e82c49ba-f14f-45a5-8f16-400d35faa06a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e82c49ba-f14f-45a5-8f16-400d35faa06a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.8919  0.9709  0.9074  0.8167  0.8596  0.7721  0.7750\n",
              "1       0.9189  0.9717  0.9259  0.8621  0.8929  0.8278  0.8291\n",
              "2       0.9459  0.9742  0.9444  0.9107  0.9273  0.8843  0.8847\n",
              "3       0.8851  0.9537  0.9259  0.7937  0.8547  0.7607  0.7668\n",
              "4       0.9527  0.9905  0.9630  0.9123  0.9369  0.8991  0.9000\n",
              "5       0.9189  0.9753  0.9259  0.8621  0.8929  0.8278  0.8291\n",
              "6       0.8784  0.9566  0.8889  0.8000  0.8421  0.7436  0.7464\n",
              "7       0.9048  0.9621  0.8519  0.8846  0.8679  0.7935  0.7938\n",
              "8       0.9116  0.9694  0.8704  0.8868  0.8785  0.8090  0.8091\n",
              "9       0.8980  0.9669  0.9057  0.8276  0.8649  0.7832  0.7852\n",
              "Mean    0.9106  0.9691  0.9109  0.8556  0.8818  0.8101  0.8119\n",
              "SD      0.0232  0.0099  0.0319  0.0417  0.0294  0.0483  0.0473"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(et_ast5_model, 'confusion_matrix')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "bf8da32ca37e42b88131b58f72c88e63",
            "19b9039175b74c95b5b8289d8c45ec40",
            "5da375e3867249768662a387e3ba6665"
          ]
        },
        "id": "6cWNXn2VPV4E",
        "outputId": "b86505f6-86c4-42c3-d6a3-e6961ba743c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(et_ast5_model, plot = 'feature')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "a1b0a34673d2418f86b93b35b52a423d",
            "16b80db8ea774676a4ce0efa3458a0fe",
            "4a3e884ca0684e7a88cc910a306f6321"
          ]
        },
        "id": "J9hXYklXQC5O",
        "outputId": "7afdcde8-db04-4724-da1f-29e79b98fc34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vy6B4jBHO2L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict_model(et_ast5_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "rjDnAi0KQWi6",
        "outputId": "244c67b9-9554-4697-d2e9-ff996726c88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f0f8af72-c03f-4ea4-b39b-7426d76894b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.9038</td>\n",
              "      <td>0.9659</td>\n",
              "      <td>0.9244</td>\n",
              "      <td>0.8365</td>\n",
              "      <td>0.8782</td>\n",
              "      <td>0.799</td>\n",
              "      <td>0.8018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0f8af72-c03f-4ea4-b39b-7426d76894b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0f8af72-c03f-4ea4-b39b-7426d76894b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0f8af72-c03f-4ea4-b39b-7426d76894b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    Model  Accuracy     AUC  ...      F1  Kappa     MCC\n",
              "0  Extra Trees Classifier    0.9038  0.9659  ...  0.8782  0.799  0.8018\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalize_model(et_ast5_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCH_S0rMQlFo",
        "outputId": "1be308be-9edc-418e-81a2-1de871d3094d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                     criterion='gini', max_depth=None, max_features='auto',\n",
              "                     max_leaf_nodes=None, max_samples=None,\n",
              "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                     min_samples_leaf=1, min_samples_split=2,\n",
              "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "                     oob_score=False, random_state=5848, verbose=0,\n",
              "                     warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(et_ast5_model, 'et_ast5_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-xZ13a4Qvb7",
        "outputId": "f22557ed-43fd-44c5-debe-d6a77b6025bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformation Pipeline and Model Successfully Saved\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Pipeline(memory=None,\n",
              "          steps=[('dtypes',\n",
              "                  DataTypes_Auto_infer(categorical_features=[],\n",
              "                                       display_types=True, features_todrop=[],\n",
              "                                       id_columns=[],\n",
              "                                       ml_usecase='classification',\n",
              "                                       numerical_features=[], target='Long',\n",
              "                                       time_features=[])),\n",
              "                 ('imputer',\n",
              "                  Simple_Imputer(categorical_strategy='not_available',\n",
              "                                 fill_value_categorical=None,\n",
              "                                 fill_value_numerical=None,\n",
              "                                 numeric_strateg...\n",
              "                  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
              "                                       class_weight=None, criterion='gini',\n",
              "                                       max_depth=None, max_features='auto',\n",
              "                                       max_leaf_nodes=None, max_samples=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=1, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       n_estimators=100, n_jobs=-1,\n",
              "                                       oob_score=False, random_state=5848,\n",
              "                                       verbose=0, warm_start=False)]],\n",
              "          verbose=False), 'et_ast5_model.pkl')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "ast1 = compare_models(sort = 'Accuracy', fold = 5, n_select = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "4d3049ceb63c491eab22ee96087677aa",
            "5c4d61fef7fc4260a9ca19af90188bec",
            "9d88d127398f446e87336a29df3cf6af"
          ]
        },
        "id": "gSMhe0dOITsY",
        "outputId": "4c531911-17be-446b-d91d-e05ae43ef314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d0fd8d1-9c11-4dc2-8053-ebf5fca35fa4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8809</td>\n",
              "      <td>0.9534</td>\n",
              "      <td>0.7936</td>\n",
              "      <td>0.8022</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>0.7131</td>\n",
              "      <td>0.7135</td>\n",
              "      <td>0.874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8775</td>\n",
              "      <td>0.9557</td>\n",
              "      <td>0.7776</td>\n",
              "      <td>0.8015</td>\n",
              "      <td>0.7890</td>\n",
              "      <td>0.7027</td>\n",
              "      <td>0.7032</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8768</td>\n",
              "      <td>0.9526</td>\n",
              "      <td>0.7661</td>\n",
              "      <td>0.8073</td>\n",
              "      <td>0.7860</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>0.7002</td>\n",
              "      <td>0.544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.8754</td>\n",
              "      <td>0.9520</td>\n",
              "      <td>0.7891</td>\n",
              "      <td>0.7889</td>\n",
              "      <td>0.7889</td>\n",
              "      <td>0.7006</td>\n",
              "      <td>0.7007</td>\n",
              "      <td>0.092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8653</td>\n",
              "      <td>0.9369</td>\n",
              "      <td>0.6951</td>\n",
              "      <td>0.8215</td>\n",
              "      <td>0.7521</td>\n",
              "      <td>0.6607</td>\n",
              "      <td>0.6657</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.8626</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6722</td>\n",
              "      <td>0.8307</td>\n",
              "      <td>0.7420</td>\n",
              "      <td>0.6499</td>\n",
              "      <td>0.6574</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.9433</td>\n",
              "      <td>0.7752</td>\n",
              "      <td>0.7633</td>\n",
              "      <td>0.7684</td>\n",
              "      <td>0.6701</td>\n",
              "      <td>0.6709</td>\n",
              "      <td>0.150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.8605</td>\n",
              "      <td>0.8337</td>\n",
              "      <td>0.7683</td>\n",
              "      <td>0.7623</td>\n",
              "      <td>0.7647</td>\n",
              "      <td>0.6657</td>\n",
              "      <td>0.6662</td>\n",
              "      <td>0.034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8592</td>\n",
              "      <td>0.9266</td>\n",
              "      <td>0.7111</td>\n",
              "      <td>0.7930</td>\n",
              "      <td>0.7487</td>\n",
              "      <td>0.6514</td>\n",
              "      <td>0.6541</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8477</td>\n",
              "      <td>0.9232</td>\n",
              "      <td>0.7983</td>\n",
              "      <td>0.7177</td>\n",
              "      <td>0.7554</td>\n",
              "      <td>0.6453</td>\n",
              "      <td>0.6477</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8436</td>\n",
              "      <td>0.8823</td>\n",
              "      <td>0.6675</td>\n",
              "      <td>0.7737</td>\n",
              "      <td>0.7162</td>\n",
              "      <td>0.6091</td>\n",
              "      <td>0.6127</td>\n",
              "      <td>0.174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.8023</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4180</td>\n",
              "      <td>0.8566</td>\n",
              "      <td>0.5266</td>\n",
              "      <td>0.4317</td>\n",
              "      <td>0.4870</td>\n",
              "      <td>0.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.9334</td>\n",
              "      <td>0.9679</td>\n",
              "      <td>0.5453</td>\n",
              "      <td>0.6975</td>\n",
              "      <td>0.5140</td>\n",
              "      <td>0.5754</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.7048</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d0fd8d1-9c11-4dc2-8053-ebf5fca35fa4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d0fd8d1-9c11-4dc2-8053-ebf5fca35fa4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d0fd8d1-9c11-4dc2-8053-ebf5fca35fa4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "rf               Random Forest Classifier    0.8809  0.9534  0.7936  0.8022   \n",
              "gbc          Gradient Boosting Classifier    0.8775  0.9557  0.7776  0.8015   \n",
              "et                 Extra Trees Classifier    0.8768  0.9526  0.7661  0.8073   \n",
              "lightgbm  Light Gradient Boosting Machine    0.8754  0.9520  0.7891  0.7889   \n",
              "lda          Linear Discriminant Analysis    0.8653  0.9369  0.6951  0.8215   \n",
              "ridge                    Ridge Classifier    0.8626  0.0000  0.6722  0.8307   \n",
              "ada                  Ada Boost Classifier    0.8619  0.9433  0.7752  0.7633   \n",
              "dt               Decision Tree Classifier    0.8605  0.8337  0.7683  0.7623   \n",
              "lr                    Logistic Regression    0.8592  0.9266  0.7111  0.7930   \n",
              "nb                            Naive Bayes    0.8477  0.9232  0.7983  0.7177   \n",
              "knn                K Neighbors Classifier    0.8436  0.8823  0.6675  0.7737   \n",
              "svm                   SVM - Linear Kernel    0.8023  0.0000  0.4180  0.8566   \n",
              "qda       Quadratic Discriminant Analysis    0.7522  0.9334  0.9679  0.5453   \n",
              "dummy                    Dummy Classifier    0.7048  0.5000  0.0000  0.0000   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "rf        0.7975  0.7131  0.7135     0.874  \n",
              "gbc       0.7890  0.7027  0.7032     0.262  \n",
              "et        0.7860  0.6995  0.7002     0.544  \n",
              "lightgbm  0.7889  0.7006  0.7007     0.092  \n",
              "lda       0.7521  0.6607  0.6657     0.018  \n",
              "ridge     0.7420  0.6499  0.6574     0.026  \n",
              "ada       0.7684  0.6701  0.6709     0.150  \n",
              "dt        0.7647  0.6657  0.6662     0.034  \n",
              "lr        0.7487  0.6514  0.6541     0.062  \n",
              "nb        0.7554  0.6453  0.6477     0.024  \n",
              "knn       0.7162  0.6091  0.6127     0.174  \n",
              "svm       0.5266  0.4317  0.4870     0.038  \n",
              "qda       0.6975  0.5140  0.5754     0.018  \n",
              "dummy     0.0000  0.0000  0.0000     0.018  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ast2 = compare_models(sort = 'Accuracy', fold = 5, n_select = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "96bab5a1fec142cabd2e9742c6c38871",
            "6a855cd761a840eb9fcfab32cd788875",
            "558aa041d7964170992a6467cb411f64"
          ]
        },
        "id": "FVnSVGOSJblg",
        "outputId": "aa610044-789a-4714-a3c7-6ae6c8ee15bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-650779a8-21ff-4224-be3b-d51b92076dd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8666</td>\n",
              "      <td>0.9405</td>\n",
              "      <td>0.7478</td>\n",
              "      <td>0.7964</td>\n",
              "      <td>0.7709</td>\n",
              "      <td>0.6771</td>\n",
              "      <td>0.6780</td>\n",
              "      <td>0.140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8660</td>\n",
              "      <td>0.9447</td>\n",
              "      <td>0.7364</td>\n",
              "      <td>0.8026</td>\n",
              "      <td>0.7674</td>\n",
              "      <td>0.6736</td>\n",
              "      <td>0.6753</td>\n",
              "      <td>0.226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8646</td>\n",
              "      <td>0.9434</td>\n",
              "      <td>0.7387</td>\n",
              "      <td>0.7977</td>\n",
              "      <td>0.7663</td>\n",
              "      <td>0.6712</td>\n",
              "      <td>0.6728</td>\n",
              "      <td>0.708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8633</td>\n",
              "      <td>0.9461</td>\n",
              "      <td>0.7319</td>\n",
              "      <td>0.7971</td>\n",
              "      <td>0.7620</td>\n",
              "      <td>0.6664</td>\n",
              "      <td>0.6685</td>\n",
              "      <td>0.588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8612</td>\n",
              "      <td>0.9251</td>\n",
              "      <td>0.6891</td>\n",
              "      <td>0.8220</td>\n",
              "      <td>0.7488</td>\n",
              "      <td>0.6540</td>\n",
              "      <td>0.6596</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.8592</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6689</td>\n",
              "      <td>0.8304</td>\n",
              "      <td>0.7401</td>\n",
              "      <td>0.6452</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.8558</td>\n",
              "      <td>0.9450</td>\n",
              "      <td>0.7455</td>\n",
              "      <td>0.7685</td>\n",
              "      <td>0.7562</td>\n",
              "      <td>0.6540</td>\n",
              "      <td>0.6547</td>\n",
              "      <td>0.090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8545</td>\n",
              "      <td>0.9340</td>\n",
              "      <td>0.7207</td>\n",
              "      <td>0.7798</td>\n",
              "      <td>0.7487</td>\n",
              "      <td>0.6465</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.8450</td>\n",
              "      <td>0.8140</td>\n",
              "      <td>0.7365</td>\n",
              "      <td>0.7457</td>\n",
              "      <td>0.7408</td>\n",
              "      <td>0.6302</td>\n",
              "      <td>0.6305</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8436</td>\n",
              "      <td>0.9253</td>\n",
              "      <td>0.8130</td>\n",
              "      <td>0.7099</td>\n",
              "      <td>0.7575</td>\n",
              "      <td>0.6429</td>\n",
              "      <td>0.6466</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8077</td>\n",
              "      <td>0.8856</td>\n",
              "      <td>0.8334</td>\n",
              "      <td>0.6388</td>\n",
              "      <td>0.7227</td>\n",
              "      <td>0.5796</td>\n",
              "      <td>0.5922</td>\n",
              "      <td>0.030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8043</td>\n",
              "      <td>0.8510</td>\n",
              "      <td>0.6149</td>\n",
              "      <td>0.6993</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.5184</td>\n",
              "      <td>0.5208</td>\n",
              "      <td>0.174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7407</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7884</td>\n",
              "      <td>0.6633</td>\n",
              "      <td>0.6378</td>\n",
              "      <td>0.4656</td>\n",
              "      <td>0.5315</td>\n",
              "      <td>0.042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.6994</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-650779a8-21ff-4224-be3b-d51b92076dd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-650779a8-21ff-4224-be3b-d51b92076dd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-650779a8-21ff-4224-be3b-d51b92076dd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "ada                  Ada Boost Classifier    0.8666  0.9405  0.7478  0.7964   \n",
              "gbc          Gradient Boosting Classifier    0.8660  0.9447  0.7364  0.8026   \n",
              "rf               Random Forest Classifier    0.8646  0.9434  0.7387  0.7977   \n",
              "et                 Extra Trees Classifier    0.8633  0.9461  0.7319  0.7971   \n",
              "lda          Linear Discriminant Analysis    0.8612  0.9251  0.6891  0.8220   \n",
              "ridge                    Ridge Classifier    0.8592  0.0000  0.6689  0.8304   \n",
              "lightgbm  Light Gradient Boosting Machine    0.8558  0.9450  0.7455  0.7685   \n",
              "lr                    Logistic Regression    0.8545  0.9340  0.7207  0.7798   \n",
              "dt               Decision Tree Classifier    0.8450  0.8140  0.7365  0.7457   \n",
              "qda       Quadratic Discriminant Analysis    0.8436  0.9253  0.8130  0.7099   \n",
              "nb                            Naive Bayes    0.8077  0.8856  0.8334  0.6388   \n",
              "knn                K Neighbors Classifier    0.8043  0.8510  0.6149  0.6993   \n",
              "svm                   SVM - Linear Kernel    0.7407  0.0000  0.7884  0.6633   \n",
              "dummy                    Dummy Classifier    0.6994  0.5000  0.0000  0.0000   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "ada       0.7709  0.6771  0.6780     0.140  \n",
              "gbc       0.7674  0.6736  0.6753     0.226  \n",
              "rf        0.7663  0.6712  0.6728     0.708  \n",
              "et        0.7620  0.6664  0.6685     0.588  \n",
              "lda       0.7488  0.6540  0.6596     0.020  \n",
              "ridge     0.7401  0.6452  0.6529     0.028  \n",
              "lightgbm  0.7562  0.6540  0.6547     0.090  \n",
              "lr        0.7487  0.6465  0.6479     0.054  \n",
              "dt        0.7408  0.6302  0.6305     0.032  \n",
              "qda       0.7575  0.6429  0.6466     0.018  \n",
              "nb        0.7227  0.5796  0.5922     0.030  \n",
              "knn       0.6539  0.5184  0.5208     0.174  \n",
              "svm       0.6378  0.4656  0.5315     0.042  \n",
              "dummy     0.0000  0.0000  0.0000     0.016  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ast3 = compare_models(sort = 'Accuracy', fold = 5, n_select = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "5ba2d65f73974962a44b001d1abce035",
            "01bdfbd6f9a642a38c1417b6f1e78fb9",
            "c2d739ae4f9b4bea8e3bf957e24acf12"
          ]
        },
        "id": "w6VCAEd1JqsW",
        "outputId": "eb879e09-1b0e-410f-e1bd-fab7f79e6ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-50f5ba0a-d4fc-4824-99d8-5479ea150914\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8991</td>\n",
              "      <td>0.9643</td>\n",
              "      <td>0.8621</td>\n",
              "      <td>0.8403</td>\n",
              "      <td>0.8499</td>\n",
              "      <td>0.7741</td>\n",
              "      <td>0.7755</td>\n",
              "      <td>0.230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8944</td>\n",
              "      <td>0.9631</td>\n",
              "      <td>0.8683</td>\n",
              "      <td>0.8237</td>\n",
              "      <td>0.8449</td>\n",
              "      <td>0.7650</td>\n",
              "      <td>0.7662</td>\n",
              "      <td>0.834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8944</td>\n",
              "      <td>0.9651</td>\n",
              "      <td>0.8601</td>\n",
              "      <td>0.8295</td>\n",
              "      <td>0.8437</td>\n",
              "      <td>0.7641</td>\n",
              "      <td>0.7652</td>\n",
              "      <td>0.562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.8924</td>\n",
              "      <td>0.9626</td>\n",
              "      <td>0.8601</td>\n",
              "      <td>0.8232</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>0.7596</td>\n",
              "      <td>0.7605</td>\n",
              "      <td>0.092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8754</td>\n",
              "      <td>0.9527</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8101</td>\n",
              "      <td>0.8122</td>\n",
              "      <td>0.7191</td>\n",
              "      <td>0.7203</td>\n",
              "      <td>0.146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.8700</td>\n",
              "      <td>0.8522</td>\n",
              "      <td>0.8003</td>\n",
              "      <td>0.8084</td>\n",
              "      <td>0.8028</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.7076</td>\n",
              "      <td>0.028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8673</td>\n",
              "      <td>0.9361</td>\n",
              "      <td>0.8437</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.8086</td>\n",
              "      <td>0.7075</td>\n",
              "      <td>0.7103</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8490</td>\n",
              "      <td>0.9374</td>\n",
              "      <td>0.7017</td>\n",
              "      <td>0.8157</td>\n",
              "      <td>0.7538</td>\n",
              "      <td>0.6459</td>\n",
              "      <td>0.6502</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8470</td>\n",
              "      <td>0.9276</td>\n",
              "      <td>0.7202</td>\n",
              "      <td>0.7969</td>\n",
              "      <td>0.7562</td>\n",
              "      <td>0.6452</td>\n",
              "      <td>0.6473</td>\n",
              "      <td>0.056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8456</td>\n",
              "      <td>0.9102</td>\n",
              "      <td>0.7778</td>\n",
              "      <td>0.7629</td>\n",
              "      <td>0.7695</td>\n",
              "      <td>0.6535</td>\n",
              "      <td>0.6544</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.8429</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6832</td>\n",
              "      <td>0.8119</td>\n",
              "      <td>0.7408</td>\n",
              "      <td>0.6295</td>\n",
              "      <td>0.6352</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8348</td>\n",
              "      <td>0.8940</td>\n",
              "      <td>0.7223</td>\n",
              "      <td>0.7679</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.6217</td>\n",
              "      <td>0.6234</td>\n",
              "      <td>0.174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7244</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4227</td>\n",
              "      <td>0.6135</td>\n",
              "      <td>0.3704</td>\n",
              "      <td>0.2769</td>\n",
              "      <td>0.3350</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.6710</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50f5ba0a-d4fc-4824-99d8-5479ea150914')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50f5ba0a-d4fc-4824-99d8-5479ea150914 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50f5ba0a-d4fc-4824-99d8-5479ea150914');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "gbc          Gradient Boosting Classifier    0.8991  0.9643  0.8621  0.8403   \n",
              "rf               Random Forest Classifier    0.8944  0.9631  0.8683  0.8237   \n",
              "et                 Extra Trees Classifier    0.8944  0.9651  0.8601  0.8295   \n",
              "lightgbm  Light Gradient Boosting Machine    0.8924  0.9626  0.8601  0.8232   \n",
              "ada                  Ada Boost Classifier    0.8754  0.9527  0.8167  0.8101   \n",
              "dt               Decision Tree Classifier    0.8700  0.8522  0.8003  0.8084   \n",
              "qda       Quadratic Discriminant Analysis    0.8673  0.9361  0.8437  0.7788   \n",
              "lda          Linear Discriminant Analysis    0.8490  0.9374  0.7017  0.8157   \n",
              "lr                    Logistic Regression    0.8470  0.9276  0.7202  0.7969   \n",
              "nb                            Naive Bayes    0.8456  0.9102  0.7778  0.7629   \n",
              "ridge                    Ridge Classifier    0.8429  0.0000  0.6832  0.8119   \n",
              "knn                K Neighbors Classifier    0.8348  0.8940  0.7223  0.7679   \n",
              "svm                   SVM - Linear Kernel    0.7244  0.0000  0.4227  0.6135   \n",
              "dummy                    Dummy Classifier    0.6710  0.5000  0.0000  0.0000   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "gbc       0.8499  0.7741  0.7755     0.230  \n",
              "rf        0.8449  0.7650  0.7662     0.834  \n",
              "et        0.8437  0.7641  0.7652     0.562  \n",
              "lightgbm  0.8408  0.7596  0.7605     0.092  \n",
              "ada       0.8122  0.7191  0.7203     0.146  \n",
              "dt        0.8028  0.7060  0.7076     0.028  \n",
              "qda       0.8086  0.7075  0.7103     0.016  \n",
              "lda       0.7538  0.6459  0.6502     0.020  \n",
              "lr        0.7562  0.6452  0.6473     0.056  \n",
              "nb        0.7695  0.6535  0.6544     0.026  \n",
              "ridge     0.7408  0.6295  0.6352     0.026  \n",
              "knn       0.7431  0.6217  0.6234     0.174  \n",
              "svm       0.3704  0.2769  0.3350     0.040  \n",
              "dummy     0.0000  0.0000  0.0000     0.016  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ast4 = compare_models(sort = 'Accuracy', fold = 5, n_select = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "b2e64910dcce4e47b90d72f407f87148",
            "0e7b0e48f64c4d45ae5c6666e5d2fa77",
            "4008127b40c84eaca60a061bc0cb9db0"
          ]
        },
        "id": "WEHsWr1-J5gL",
        "outputId": "d638a0ef-4d13-426b-cfd0-3fb8d1669e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7a786a0-3322-40f8-b2d9-1d4cedcadbeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.9005</td>\n",
              "      <td>0.9626</td>\n",
              "      <td>0.9494</td>\n",
              "      <td>0.8755</td>\n",
              "      <td>0.9108</td>\n",
              "      <td>0.7986</td>\n",
              "      <td>0.8025</td>\n",
              "      <td>0.640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8917</td>\n",
              "      <td>0.9628</td>\n",
              "      <td>0.9380</td>\n",
              "      <td>0.8703</td>\n",
              "      <td>0.9027</td>\n",
              "      <td>0.7809</td>\n",
              "      <td>0.7841</td>\n",
              "      <td>0.546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8910</td>\n",
              "      <td>0.9612</td>\n",
              "      <td>0.9456</td>\n",
              "      <td>0.8639</td>\n",
              "      <td>0.9028</td>\n",
              "      <td>0.7793</td>\n",
              "      <td>0.7838</td>\n",
              "      <td>0.232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.8910</td>\n",
              "      <td>0.9637</td>\n",
              "      <td>0.9229</td>\n",
              "      <td>0.8798</td>\n",
              "      <td>0.9007</td>\n",
              "      <td>0.7800</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>0.088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>0.9592</td>\n",
              "      <td>0.9229</td>\n",
              "      <td>0.8674</td>\n",
              "      <td>0.8941</td>\n",
              "      <td>0.7633</td>\n",
              "      <td>0.7656</td>\n",
              "      <td>0.152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.8659</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8672</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>0.8735</td>\n",
              "      <td>0.7309</td>\n",
              "      <td>0.7321</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8646</td>\n",
              "      <td>0.9492</td>\n",
              "      <td>0.8647</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.8721</td>\n",
              "      <td>0.7282</td>\n",
              "      <td>0.7295</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.9507</td>\n",
              "      <td>0.8748</td>\n",
              "      <td>0.8686</td>\n",
              "      <td>0.8713</td>\n",
              "      <td>0.7222</td>\n",
              "      <td>0.7231</td>\n",
              "      <td>0.038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.8585</td>\n",
              "      <td>0.8589</td>\n",
              "      <td>0.8521</td>\n",
              "      <td>0.8805</td>\n",
              "      <td>0.8655</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>0.7176</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8585</td>\n",
              "      <td>0.9423</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>0.8582</td>\n",
              "      <td>0.8694</td>\n",
              "      <td>0.7150</td>\n",
              "      <td>0.7156</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8517</td>\n",
              "      <td>0.9267</td>\n",
              "      <td>0.8584</td>\n",
              "      <td>0.8644</td>\n",
              "      <td>0.8609</td>\n",
              "      <td>0.7021</td>\n",
              "      <td>0.7031</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8152</td>\n",
              "      <td>0.8709</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.8120</td>\n",
              "      <td>0.8319</td>\n",
              "      <td>0.6269</td>\n",
              "      <td>0.6284</td>\n",
              "      <td>0.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7943</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7438</td>\n",
              "      <td>0.8872</td>\n",
              "      <td>0.7795</td>\n",
              "      <td>0.5924</td>\n",
              "      <td>0.6315</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.6975</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7a786a0-3322-40f8-b2d9-1d4cedcadbeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7a786a0-3322-40f8-b2d9-1d4cedcadbeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7a786a0-3322-40f8-b2d9-1d4cedcadbeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "rf               Random Forest Classifier    0.9005  0.9626  0.9494  0.8755   \n",
              "et                 Extra Trees Classifier    0.8917  0.9628  0.9380  0.8703   \n",
              "gbc          Gradient Boosting Classifier    0.8910  0.9612  0.9456  0.8639   \n",
              "lightgbm  Light Gradient Boosting Machine    0.8910  0.9637  0.9229  0.8798   \n",
              "ada                  Ada Boost Classifier    0.8829  0.9592  0.9229  0.8674   \n",
              "ridge                    Ridge Classifier    0.8659  0.0000  0.8672  0.8811   \n",
              "lda          Linear Discriminant Analysis    0.8646  0.9492  0.8647  0.8808   \n",
              "lr                    Logistic Regression    0.8619  0.9507  0.8748  0.8686   \n",
              "dt               Decision Tree Classifier    0.8585  0.8589  0.8521  0.8805   \n",
              "qda       Quadratic Discriminant Analysis    0.8585  0.9423  0.8811  0.8582   \n",
              "nb                            Naive Bayes    0.8517  0.9267  0.8584  0.8644   \n",
              "knn                K Neighbors Classifier    0.8152  0.8709  0.8533  0.8120   \n",
              "svm                   SVM - Linear Kernel    0.7943  0.0000  0.7438  0.8872   \n",
              "dummy                    Dummy Classifier    0.5355  0.5000  1.0000  0.5355   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "rf        0.9108  0.7986  0.8025     0.640  \n",
              "et        0.9027  0.7809  0.7841     0.546  \n",
              "gbc       0.9028  0.7793  0.7838     0.232  \n",
              "lightgbm  0.9007  0.7800  0.7813     0.088  \n",
              "ada       0.8941  0.7633  0.7656     0.152  \n",
              "ridge     0.8735  0.7309  0.7321     0.018  \n",
              "lda       0.8721  0.7282  0.7295     0.018  \n",
              "lr        0.8713  0.7222  0.7231     0.038  \n",
              "dt        0.8655  0.7163  0.7176     0.024  \n",
              "qda       0.8694  0.7150  0.7156     0.020  \n",
              "nb        0.8609  0.7021  0.7031     0.018  \n",
              "knn       0.8319  0.6269  0.6284     0.142  \n",
              "svm       0.7795  0.5924  0.6315     0.024  \n",
              "dummy     0.6975  0.0000  0.0000     0.014  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ast5 = compare_models(sort = 'Accuracy', fold = 5, n_select = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "15b26ebcc41f4e5c9dd51964e73d03a4",
            "4fca724191624095a8995664f9ff4084",
            "d3de5afc889746ddb635ba7b7c481b12"
          ]
        },
        "id": "mOVOXmx_KKSz",
        "outputId": "346a5176-a4cf-4611-dfe2-18bacb64c389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-51e89559-5f6a-469d-af8d-06c079724010\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.9059</td>\n",
              "      <td>0.9666</td>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.8284</td>\n",
              "      <td>0.8788</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.8071</td>\n",
              "      <td>0.744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.9032</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.9255</td>\n",
              "      <td>0.8289</td>\n",
              "      <td>0.8744</td>\n",
              "      <td>0.7960</td>\n",
              "      <td>0.7995</td>\n",
              "      <td>0.544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.9018</td>\n",
              "      <td>0.9652</td>\n",
              "      <td>0.9330</td>\n",
              "      <td>0.8221</td>\n",
              "      <td>0.8738</td>\n",
              "      <td>0.7940</td>\n",
              "      <td>0.7986</td>\n",
              "      <td>0.258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.8978</td>\n",
              "      <td>0.9656</td>\n",
              "      <td>0.8959</td>\n",
              "      <td>0.8359</td>\n",
              "      <td>0.8647</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.7841</td>\n",
              "      <td>0.096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8917</td>\n",
              "      <td>0.9593</td>\n",
              "      <td>0.8940</td>\n",
              "      <td>0.8241</td>\n",
              "      <td>0.8568</td>\n",
              "      <td>0.7699</td>\n",
              "      <td>0.7727</td>\n",
              "      <td>0.152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.8863</td>\n",
              "      <td>0.8800</td>\n",
              "      <td>0.8568</td>\n",
              "      <td>0.8356</td>\n",
              "      <td>0.8459</td>\n",
              "      <td>0.7558</td>\n",
              "      <td>0.7562</td>\n",
              "      <td>0.034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8775</td>\n",
              "      <td>0.9541</td>\n",
              "      <td>0.8326</td>\n",
              "      <td>0.8315</td>\n",
              "      <td>0.8316</td>\n",
              "      <td>0.7353</td>\n",
              "      <td>0.7358</td>\n",
              "      <td>0.064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8659</td>\n",
              "      <td>0.9489</td>\n",
              "      <td>0.8009</td>\n",
              "      <td>0.8262</td>\n",
              "      <td>0.8122</td>\n",
              "      <td>0.7081</td>\n",
              "      <td>0.7095</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.8646</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7972</td>\n",
              "      <td>0.8254</td>\n",
              "      <td>0.8099</td>\n",
              "      <td>0.7049</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8599</td>\n",
              "      <td>0.9281</td>\n",
              "      <td>0.8214</td>\n",
              "      <td>0.8006</td>\n",
              "      <td>0.8099</td>\n",
              "      <td>0.6990</td>\n",
              "      <td>0.7002</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8470</td>\n",
              "      <td>0.9445</td>\n",
              "      <td>0.9349</td>\n",
              "      <td>0.7263</td>\n",
              "      <td>0.8171</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8395</td>\n",
              "      <td>0.8968</td>\n",
              "      <td>0.7564</td>\n",
              "      <td>0.7938</td>\n",
              "      <td>0.7741</td>\n",
              "      <td>0.6499</td>\n",
              "      <td>0.6508</td>\n",
              "      <td>0.172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7725</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5141</td>\n",
              "      <td>0.8684</td>\n",
              "      <td>0.5282</td>\n",
              "      <td>0.4385</td>\n",
              "      <td>0.4874</td>\n",
              "      <td>0.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.6357</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51e89559-5f6a-469d-af8d-06c079724010')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51e89559-5f6a-469d-af8d-06c079724010 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51e89559-5f6a-469d-af8d-06c079724010');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "rf               Random Forest Classifier    0.9059  0.9666  0.9367  0.8284   \n",
              "et                 Extra Trees Classifier    0.9032  0.9700  0.9255  0.8289   \n",
              "gbc          Gradient Boosting Classifier    0.9018  0.9652  0.9330  0.8221   \n",
              "lightgbm  Light Gradient Boosting Machine    0.8978  0.9656  0.8959  0.8359   \n",
              "ada                  Ada Boost Classifier    0.8917  0.9593  0.8940  0.8241   \n",
              "dt               Decision Tree Classifier    0.8863  0.8800  0.8568  0.8356   \n",
              "lr                    Logistic Regression    0.8775  0.9541  0.8326  0.8315   \n",
              "lda          Linear Discriminant Analysis    0.8659  0.9489  0.8009  0.8262   \n",
              "ridge                    Ridge Classifier    0.8646  0.0000  0.7972  0.8254   \n",
              "nb                            Naive Bayes    0.8599  0.9281  0.8214  0.8006   \n",
              "qda       Quadratic Discriminant Analysis    0.8470  0.9445  0.9349  0.7263   \n",
              "knn                K Neighbors Classifier    0.8395  0.8968  0.7564  0.7938   \n",
              "svm                   SVM - Linear Kernel    0.7725  0.0000  0.5141  0.8684   \n",
              "dummy                    Dummy Classifier    0.6357  0.5000  0.0000  0.0000   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "rf        0.8788  0.8024  0.8071     0.744  \n",
              "et        0.8744  0.7960  0.7995     0.544  \n",
              "gbc       0.8738  0.7940  0.7986     0.258  \n",
              "lightgbm  0.8647  0.7827  0.7841     0.096  \n",
              "ada       0.8568  0.7699  0.7727     0.152  \n",
              "dt        0.8459  0.7558  0.7562     0.034  \n",
              "lr        0.8316  0.7353  0.7358     0.064  \n",
              "lda       0.8122  0.7081  0.7095     0.018  \n",
              "ridge     0.8099  0.7049  0.7063     0.024  \n",
              "nb        0.8099  0.6990  0.7002     0.032  \n",
              "qda       0.8171  0.6894  0.7061     0.018  \n",
              "knn       0.7741  0.6499  0.6508     0.172  \n",
              "svm       0.5282  0.4385  0.4874     0.032  \n",
              "dummy     0.0000  0.0000  0.0000     0.014  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step**\n",
        "  * step เป็นตัวรับส่งคำสั่งซื้อขาย และขยับเวลา"
      ],
      "metadata": {
        "id": "rCgws9VDhcI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getCashBalance()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Nyd4PDvy_M",
        "outputId": "3be2e7d9-b715-45f9-ea29-380f5072f85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb6_4VfHKyma",
        "outputId": "f564d6b0-6a27-4026-967e-4d1797ac3a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Note': 'Unable to close order. !!!', 'Position id': 'Invalid'}]"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "te0q9Cx2WMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setPosition(asset, buy, order, i, j, id, action):\n",
        "  if buy[j] !=1 :\n",
        "    if observers.getDataset()[asset]['MACD'][i] > 0 or observers.getDataset()[asset]['RSI'][i] < 40 or observers.getDataset()[asset]['ROC'][i] < 0 :\n",
        "      order = [{'symbol':asset,'open_long':observers.getCashBalance()*0.3}]\n",
        "     # order.append({'symbol':asset,'open_long':observers.getCashBalance()*0.2})\n",
        "      action[asset] = id\n",
        "      id += 1\n",
        "      #order.append({'symbol':asset,'close_short':18000})\n",
        "      buy[j] = 1\n",
        "  else:\n",
        "    if observers.getDataset()[asset]['MACD'][i] < 0  or observers.getDataset()[asset]['RSI'][i] > 70  :\n",
        "   #   order.append({'symbol':asset,'close_long':action[j]})\n",
        "      order = [{'symbol':asset,'close_long':action[asset]}]\n",
        "      action.pop(asset)\n",
        "      #order.append({'symbol':asset,'open_short':18000})\n",
        "      buy[j] = 0\n",
        "  return buy, order, id, action"
      ],
      "metadata": {
        "id": "dIeyeInZbLKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buy = [0,0,0,0,0]\n",
        "id = 1\n",
        "action = {}\n",
        "\n",
        "try:\n",
        "  for i in range(len(observers.getDataset()['Asset01']['close'])):\n",
        "    order = []\n",
        "    for j in range(len(observers.getDataset())):\n",
        "      buy, order, id, action = setPosition('Asset0'+format(j+1), buy, order, i, j, id, action)\n",
        "      if order != []:\n",
        "        break\n",
        "    print('Record '+format(i)+' : '+format(order))\n",
        "    # if i >= (len(observers.getDataset()['Asset01']['CDC'])):\n",
        "    #   break\n",
        "    status,price_df,liq_position,done = observers.step(order)\n",
        "except NameError:\n",
        "  print(NameError)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f5MDOrmk8OSu",
        "outputId": "b37f6c59-9f26-4883-f44a-cf587d1997d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record 0 : []\n",
            "Record 1 : []\n",
            "Record 2 : []\n",
            "Record 3 : []\n",
            "Record 4 : []\n",
            "Record 5 : [{'symbol': 'Asset02', 'open_long': 30000.0}]\n",
            "Record 6 : [{'symbol': 'Asset04', 'open_long': 21000.0}]\n",
            "Record 7 : [{'symbol': 'Asset01', 'open_long': 14700.0}]\n",
            "Record 8 : [{'symbol': 'Asset03', 'open_long': 10290.0}]\n",
            "Record 9 : [{'symbol': 'Asset05', 'open_long': 7203.0}]\n",
            "Record 10 : []\n",
            "Record 11 : []\n",
            "Record 12 : []\n",
            "Record 13 : []\n",
            "Record 14 : []\n",
            "Record 15 : [{'symbol': 'Asset03', 'close_long': 4}]\n",
            "Record 16 : []\n",
            "Record 17 : []\n",
            "Record 18 : []\n",
            "Record 19 : []\n",
            "Record 20 : [{'symbol': 'Asset03', 'open_long': 8102.703107461715}]\n",
            "Record 21 : []\n",
            "Record 22 : []\n",
            "Record 23 : []\n",
            "Record 24 : [{'symbol': 'Asset03', 'close_long': 6}]\n",
            "Record 25 : []\n",
            "Record 26 : []\n",
            "Record 27 : []\n",
            "Record 28 : []\n",
            "Record 29 : []\n",
            "Record 30 : []\n",
            "Record 31 : []\n",
            "Record 32 : []\n",
            "Record 33 : [{'symbol': 'Asset02', 'close_long': 1}]\n",
            "Record 34 : [{'symbol': 'Asset03', 'open_long': 17863.792446431962}]\n",
            "Record 35 : [{'symbol': 'Asset03', 'close_long': 7}]\n",
            "Record 36 : [{'symbol': 'Asset03', 'open_long': 17792.611045139613}]\n",
            "Record 37 : [{'symbol': 'Asset04', 'close_long': 2}]\n",
            "Record 38 : [{'symbol': 'Asset04', 'open_long': 19270.948292160498}]\n",
            "Record 39 : [{'symbol': 'Asset04', 'close_long': 9}]\n",
            "Record 40 : [{'symbol': 'Asset02', 'open_long': 19196.022296428815}]\n",
            "Record 41 : [{'symbol': 'Asset05', 'close_long': 5}]\n",
            "Record 42 : [{'symbol': 'Asset04', 'open_long': 15979.986052136404}]\n",
            "Record 43 : []\n",
            "Record 44 : [{'symbol': 'Asset05', 'open_long': 11185.990236495485}]\n",
            "Record 45 : [{'symbol': 'Asset01', 'close_long': 3}]\n",
            "Record 46 : []\n",
            "Record 47 : []\n",
            "Record 48 : [{'symbol': 'Asset01', 'open_long': 12183.269690628647}]\n",
            "Record 49 : [{'symbol': 'Asset03', 'close_long': 8}]\n",
            "Record 50 : [{'symbol': 'Asset03', 'open_long': 13950.223842049441}]\n",
            "Record 51 : [{'symbol': 'Asset03', 'close_long': 14}]\n",
            "Record 52 : [{'symbol': 'Asset01', 'close_long': 13}]\n",
            "Record 53 : [{'symbol': 'Asset01', 'open_long': 17582.573122974467}]\n",
            "Record 54 : [{'symbol': 'Asset01', 'close_long': 15}]\n",
            "Record 55 : [{'symbol': 'Asset01', 'open_long': 17566.68948831669}]\n",
            "Record 56 : [{'symbol': 'Asset01', 'close_long': 16}]\n",
            "Record 57 : [{'symbol': 'Asset03', 'open_long': 17560.173951662196}]\n",
            "Record 58 : [{'symbol': 'Asset03', 'close_long': 17}]\n",
            "Record 59 : [{'symbol': 'Asset03', 'open_long': 17555.552402920766}]\n",
            "Record 60 : [{'symbol': 'Asset05', 'close_long': 12}]\n",
            "Record 61 : [{'symbol': 'Asset05', 'open_long': 15926.920938478454}]\n",
            "Record 62 : [{'symbol': 'Asset05', 'close_long': 19}]\n",
            "Record 63 : [{'symbol': 'Asset05', 'open_long': 15926.438426479672}]\n",
            "Record 64 : [{'symbol': 'Asset05', 'close_long': 20}]\n",
            "Record 65 : [{'symbol': 'Asset05', 'open_long': 15920.617476241898}]\n",
            "Record 66 : [{'symbol': 'Asset01', 'open_long': 11144.432233369329}]\n",
            "Record 67 : [{'symbol': 'Asset01', 'close_long': 22}]\n",
            "Record 68 : [{'symbol': 'Asset01', 'open_long': 11146.111657031584}]\n",
            "Record 69 : [{'symbol': 'Asset01', 'close_long': 23}]\n",
            "Record 70 : [{'symbol': 'Asset01', 'open_long': 11151.023568737377}]\n",
            "Record 71 : [{'symbol': 'Asset01', 'close_long': 24}]\n",
            "Record 72 : [{'symbol': 'Asset01', 'open_long': 11126.373709073468}]\n",
            "Record 73 : [{'symbol': 'Asset01', 'close_long': 25}]\n",
            "Record 74 : [{'symbol': 'Asset03', 'close_long': 18}]\n",
            "Record 75 : [{'symbol': 'Asset04', 'close_long': 11}]\n",
            "Record 76 : [{'symbol': 'Asset04', 'open_long': 21651.41919067021}]\n",
            "Record 77 : [{'symbol': 'Asset04', 'close_long': 26}]\n",
            "Record 78 : [{'symbol': 'Asset03', 'open_long': 21645.706322170976}]\n",
            "Record 79 : [{'symbol': 'Asset01', 'open_long': 15151.994425519684}]\n",
            "Record 80 : [{'symbol': 'Asset01', 'close_long': 28}]\n",
            "Record 81 : [{'symbol': 'Asset01', 'open_long': 15141.072622679849}]\n",
            "Record 82 : [{'symbol': 'Asset01', 'close_long': 29}]\n",
            "Record 83 : [{'symbol': 'Asset01', 'open_long': 15126.660106463543}]\n",
            "Record 84 : [{'symbol': 'Asset01', 'close_long': 30}]\n",
            "Record 85 : [{'symbol': 'Asset01', 'open_long': 15126.485113547296}]\n",
            "Record 86 : [{'symbol': 'Asset01', 'close_long': 31}]\n",
            "Record 87 : [{'symbol': 'Asset01', 'open_long': 15118.629880098215}]\n",
            "Record 88 : [{'symbol': 'Asset01', 'close_long': 32}]\n",
            "Record 89 : [{'symbol': 'Asset01', 'open_long': 15124.608642342537}]\n",
            "Record 90 : [{'symbol': 'Asset01', 'close_long': 33}]\n",
            "Record 91 : [{'symbol': 'Asset02', 'close_long': 10}]\n",
            "Record 92 : [{'symbol': 'Asset02', 'open_long': 20916.803649709997}]\n",
            "Record 93 : [{'symbol': 'Asset03', 'close_long': 27}]\n",
            "Record 94 : [{'symbol': 'Asset04', 'open_long': 21317.007730899415}]\n",
            "Record 95 : [{'symbol': 'Asset03', 'open_long': 14921.905411629592}]\n",
            "Record 96 : [{'symbol': 'Asset03', 'close_long': 36}]\n",
            "Record 97 : [{'symbol': 'Asset03', 'open_long': 14949.641958533699}]\n",
            "Record 98 : [{'symbol': 'Asset01', 'open_long': 10464.749370973588}]\n",
            "Record 99 : [{'symbol': 'Asset01', 'close_long': 38}]\n",
            "Record 100 : [{'symbol': 'Asset01', 'open_long': 10451.519097470196}]\n",
            "Record 101 : [{'symbol': 'Asset01', 'close_long': 39}]\n",
            "Record 102 : [{'symbol': 'Asset01', 'open_long': 10430.729384487036}]\n",
            "Record 103 : [{'symbol': 'Asset01', 'close_long': 40}]\n",
            "Record 104 : [{'symbol': 'Asset01', 'open_long': 10421.48129039009}]\n",
            "Record 105 : [{'symbol': 'Asset01', 'close_long': 41}]\n",
            "Record 106 : [{'symbol': 'Asset03', 'close_long': 37}]\n",
            "Record 107 : [{'symbol': 'Asset05', 'close_long': 21}]\n",
            "Record 108 : [{'symbol': 'Asset05', 'open_long': 19678.048052149752}]\n",
            "Record 109 : [{'symbol': 'Asset05', 'close_long': 42}]\n",
            "Record 110 : [{'symbol': 'Asset05', 'open_long': 19661.873276059847}]\n",
            "Record 111 : [{'symbol': 'Asset05', 'close_long': 43}]\n",
            "Record 112 : [{'symbol': 'Asset01', 'open_long': 19621.921555973113}]\n",
            "Record 113 : [{'symbol': 'Asset01', 'close_long': 44}]\n",
            "Record 114 : [{'symbol': 'Asset01', 'open_long': 19617.52596058777}]\n",
            "Record 115 : [{'symbol': 'Asset01', 'close_long': 45}]\n",
            "Record 116 : [{'symbol': 'Asset01', 'open_long': 19585.39065783891}]\n",
            "Record 117 : [{'symbol': 'Asset01', 'close_long': 46}]\n",
            "Record 118 : [{'symbol': 'Asset02', 'close_long': 34}]\n",
            "Record 119 : [{'symbol': 'Asset01', 'open_long': 26659.535595673307}]\n",
            "Record 120 : [{'symbol': 'Asset01', 'close_long': 47}]\n",
            "Record 121 : [{'symbol': 'Asset01', 'open_long': 26664.99809726382}]\n",
            "Record 122 : [{'symbol': 'Asset01', 'close_long': 48}]\n",
            "Record 123 : [{'symbol': 'Asset02', 'open_long': 26624.945212978604}]\n",
            "Record 124 : [{'symbol': 'Asset02', 'close_long': 49}]\n",
            "Record 125 : [{'symbol': 'Asset02', 'open_long': 26410.525208141273}]\n",
            "Record 126 : [{'symbol': 'Asset01', 'open_long': 18487.36764569889}]\n",
            "Record 127 : [{'symbol': 'Asset02', 'close_long': 50}]\n",
            "Record 128 : [{'symbol': 'Asset02', 'open_long': 21020.21332283756}]\n",
            "Record 129 : [{'symbol': 'Asset02', 'close_long': 52}]\n",
            "Record 130 : [{'symbol': 'Asset02', 'open_long': 21030.955789825573}]\n",
            "Record 131 : [{'symbol': 'Asset02', 'close_long': 53}]\n",
            "Record 132 : [{'symbol': 'Asset02', 'open_long': 21101.066476891116}]\n",
            "Record 133 : [{'symbol': 'Asset02', 'close_long': 54}]\n",
            "Record 134 : [{'symbol': 'Asset03', 'open_long': 21153.753492232634}]\n",
            "Record 135 : [{'symbol': 'Asset03', 'close_long': 55}]\n",
            "Record 136 : [{'symbol': 'Asset03', 'open_long': 21258.906072320387}]\n",
            "Record 137 : [{'symbol': 'Asset03', 'close_long': 56}]\n",
            "Record 138 : [{'symbol': 'Asset03', 'open_long': 21287.74348013393}]\n",
            "Record 139 : [{'symbol': 'Asset03', 'close_long': 57}]\n",
            "Record 140 : [{'symbol': 'Asset03', 'open_long': 21241.993046341784}]\n",
            "Record 141 : [{'symbol': 'Asset02', 'open_long': 14869.39513243925}]\n",
            "Record 142 : [{'symbol': 'Asset05', 'open_long': 10408.576592707475}]\n",
            "Record 143 : []\n",
            "Record 144 : [{'symbol': 'Asset03', 'close_long': 58}]\n",
            "Record 145 : [{'symbol': 'Asset03', 'open_long': 13751.361293587848}]\n",
            "Record 146 : []\n",
            "Record 147 : []\n",
            "Record 148 : []\n",
            "Record 149 : [{'symbol': 'Asset01', 'close_long': 51}]\n",
            "Record 150 : [{'symbol': 'Asset05', 'close_long': 60}]\n",
            "Record 151 : []\n",
            "Record 152 : []\n",
            "Record 153 : [{'symbol': 'Asset01', 'open_long': 18335.509453104412}]\n",
            "Record 154 : [{'symbol': 'Asset01', 'close_long': 62}]\n",
            "Record 155 : [{'symbol': 'Asset01', 'open_long': 18320.83875911102}]\n",
            "Record 156 : [{'symbol': 'Asset01', 'close_long': 63}]\n",
            "Record 157 : [{'symbol': 'Asset01', 'open_long': 18308.4467058856}]\n",
            "Record 158 : [{'symbol': 'Asset01', 'close_long': 64}]\n",
            "Record 159 : [{'symbol': 'Asset01', 'open_long': 18303.65567870805}]\n",
            "Record 160 : [{'symbol': 'Asset01', 'close_long': 65}]\n",
            "Record 161 : [{'symbol': 'Asset01', 'open_long': 18310.809922303688}]\n",
            "Record 162 : [{'symbol': 'Asset01', 'close_long': 66}]\n",
            "Record 163 : [{'symbol': 'Asset01', 'open_long': 18290.01407470374}]\n",
            "Record 164 : [{'symbol': 'Asset01', 'close_long': 67}]\n",
            "Record 165 : [{'symbol': 'Asset01', 'open_long': 18253.91187511753}]\n",
            "Record 166 : [{'symbol': 'Asset01', 'close_long': 68}]\n",
            "Record 167 : [{'symbol': 'Asset02', 'close_long': 59}]\n",
            "Record 168 : [{'symbol': 'Asset02', 'open_long': 22945.391881625368}]\n",
            "Record 169 : [{'symbol': 'Asset02', 'close_long': 69}]\n",
            "Record 170 : [{'symbol': 'Asset02', 'open_long': 23005.00842011076}]\n",
            "Record 171 : [{'symbol': 'Asset02', 'close_long': 70}]\n",
            "Record 172 : [{'symbol': 'Asset01', 'open_long': 22903.192623373732}]\n",
            "Record 173 : [{'symbol': 'Asset01', 'close_long': 71}]\n",
            "Record 174 : [{'symbol': 'Asset01', 'open_long': 22911.088625132226}]\n",
            "Record 175 : [{'symbol': 'Asset01', 'close_long': 72}]\n",
            "Record 176 : [{'symbol': 'Asset01', 'open_long': 22941.445351708102}]\n",
            "Record 177 : [{'symbol': 'Asset01', 'close_long': 73}]\n",
            "Record 178 : [{'symbol': 'Asset01', 'open_long': 22957.252654206834}]\n",
            "Record 179 : [{'symbol': 'Asset01', 'close_long': 74}]\n",
            "Record 180 : [{'symbol': 'Asset02', 'open_long': 22944.94715324742}]\n",
            "Record 181 : [{'symbol': 'Asset02', 'close_long': 75}]\n",
            "Record 182 : [{'symbol': 'Asset01', 'open_long': 23011.07340834388}]\n",
            "Record 183 : [{'symbol': 'Asset01', 'close_long': 76}]\n",
            "Record 184 : [{'symbol': 'Asset01', 'open_long': 23033.767142072444}]\n",
            "Record 185 : [{'symbol': 'Asset01', 'close_long': 77}]\n",
            "Record 186 : [{'symbol': 'Asset01', 'open_long': 23013.128756895818}]\n",
            "Record 187 : [{'symbol': 'Asset01', 'close_long': 78}]\n",
            "Record 188 : [{'symbol': 'Asset01', 'open_long': 22991.4913767788}]\n",
            "Record 189 : [{'symbol': 'Asset01', 'close_long': 79}]\n",
            "Record 190 : [{'symbol': 'Asset02', 'open_long': 22998.415504007007}]\n",
            "Record 191 : [{'symbol': 'Asset05', 'open_long': 16098.890852804905}]\n",
            "Record 192 : [{'symbol': 'Asset01', 'open_long': 11269.223596963433}]\n",
            "Record 193 : [{'symbol': 'Asset01', 'close_long': 82}]\n",
            "Record 194 : [{'symbol': 'Asset01', 'open_long': 11270.578749457847}]\n",
            "Record 195 : [{'symbol': 'Asset01', 'close_long': 83}]\n",
            "Record 196 : [{'symbol': 'Asset01', 'open_long': 11251.782354544981}]\n",
            "Record 197 : [{'symbol': 'Asset01', 'close_long': 84}]\n",
            "Record 198 : [{'symbol': 'Asset01', 'open_long': 11244.175217450056}]\n",
            "Record 199 : [{'symbol': 'Asset01', 'close_long': 85}]\n",
            "Record 200 : [{'symbol': 'Asset01', 'open_long': 11245.576060665919}]\n",
            "Record 201 : [{'symbol': 'Asset01', 'close_long': 86}]\n",
            "Record 202 : [{'symbol': 'Asset01', 'open_long': 11241.805936809405}]\n",
            "Record 203 : [{'symbol': 'Asset01', 'close_long': 87}]\n",
            "Record 204 : [{'symbol': 'Asset01', 'open_long': 11248.372976971486}]\n",
            "Record 205 : [{'symbol': 'Asset01', 'close_long': 88}]\n",
            "Record 206 : [{'symbol': 'Asset02', 'close_long': 80}]\n",
            "Record 207 : [{'symbol': 'Asset02', 'open_long': 18336.447333084616}]\n",
            "Record 208 : [{'symbol': 'Asset02', 'close_long': 89}]\n",
            "Record 209 : [{'symbol': 'Asset02', 'open_long': 18256.045413660486}]\n",
            "Record 210 : [{'symbol': 'Asset02', 'close_long': 90}]\n",
            "Record 211 : [{'symbol': 'Asset03', 'close_long': 61}]\n",
            "Record 212 : [{'symbol': 'Asset03', 'open_long': 22250.43934044272}]\n",
            "Record 213 : [{'symbol': 'Asset01', 'open_long': 15575.307538309902}]\n",
            "Record 214 : [{'symbol': 'Asset02', 'open_long': 10902.71527681693}]\n",
            "Record 215 : [{'symbol': 'Asset02', 'close_long': 93}]\n",
            "Record 216 : [{'symbol': 'Asset03', 'close_long': 91}]\n",
            "Record 217 : []\n",
            "Record 218 : []\n",
            "Record 219 : []\n",
            "Record 220 : []\n",
            "Record 221 : [{'symbol': 'Asset02', 'open_long': 17757.055378926827}]\n",
            "Record 222 : [{'symbol': 'Asset02', 'close_long': 94}]\n",
            "Record 223 : [{'symbol': 'Asset02', 'open_long': 17832.844189283827}]\n",
            "Record 224 : [{'symbol': 'Asset03', 'open_long': 12482.990932498678}]\n",
            "Record 225 : []\n",
            "Record 226 : [{'symbol': 'Asset03', 'close_long': 96}]\n",
            "Record 227 : [{'symbol': 'Asset03', 'open_long': 12489.130807082363}]\n",
            "Record 228 : [{'symbol': 'Asset03', 'close_long': 97}]\n",
            "Record 229 : [{'symbol': 'Asset03', 'open_long': 12505.935584895315}]\n",
            "Record 230 : [{'symbol': 'Asset01', 'close_long': 92}]\n",
            "Record 231 : [{'symbol': 'Asset01', 'open_long': 13431.01716020138}]\n",
            "Record 232 : [{'symbol': 'Asset01', 'close_long': 99}]\n",
            "Record 233 : [{'symbol': 'Asset03', 'close_long': 98}]\n",
            "Record 234 : [{'symbol': 'Asset04', 'close_long': 35}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-207-c931c00942ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# if i >= (len(observers.getDataset()['Asset01']['CDC'])):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#   break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprice_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mliq_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNameError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deepinvest_open_environment/Observer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, sent_order)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCodeAsset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCodeAsset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mhisOrder_dict\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Order'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4603\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4604\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 264 is out of bounds for axis 0 with size 264"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd = pd.DataFrame({'EMA12':observers.getDataset()['Asset01']['EMA12'] , 'EMA26':observers.getDataset()['Asset01']['EMA26']})"
      ],
      "metadata": {
        "id": "6j7Y3c5t_DQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_dr8xG1xskR",
        "outputId": "e56c9f80-7a11-4d50-bcfa-7d9d4cee47a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Asset02': 89, 'Asset04': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd"
      ],
      "metadata": {
        "id": "qiYmOMHNBfkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getPosition()"
      ],
      "metadata": {
        "id": "FJGDrMaYbTzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getLogOrder()"
      ],
      "metadata": {
        "id": "bd6Uxm1xt3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getLogWallet().tail(5)"
      ],
      "metadata": {
        "id": "cp6mQrY1iLCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getCashBalance()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfhvsS_zfM4n",
        "outputId": "407447f6-f4ac-4c0c-87b2-1b92f58ae5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119672.2796163075"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getLogPosition()"
      ],
      "metadata": {
        "id": "yqyFFY13iLCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order = [{'symbol':'Asset01','close_all':1},{'symbol':'Asset02','close_short':4}]\n",
        "status,price_df,liq_position,done = observers.step(order)"
      ],
      "metadata": {
        "id": "3f-NkP4viiqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getLogWallet().tail(5)"
      ],
      "metadata": {
        "id": "sK8u75gAiiqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getPosition()"
      ],
      "metadata": {
        "id": "MuqmS2Ooiiqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getLogPosition()"
      ],
      "metadata": {
        "id": "Laa93pcjiiqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**getLogOrder**\n",
        "  getLogOrder เป็น Dataframe ที่บันทึกการซื้ขายทั้งหมด\n",
        "  * เมื่อต้องการที่จะส่งคำตอบ ให้ประกาศ Observers(window,train=False) หลังจากนั้นทำการซื้อขายตามโมเดลที่สร้างมา getLogOrder จะเก็บข้อมูลการซื้อขายทั้งหมดในชุด test ซึ่ง dataframตัวนี้จำเป็นต้องนำส่งเพื่อตรวจคำตอบ"
      ],
      "metadata": {
        "id": "5ongBxgvjvsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getLogOrder()"
      ],
      "metadata": {
        "id": "wQMuLD3DiulR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**save_csv**\n",
        "  * save_csv บันทึกข้อมูลลงไฟล์ csv\n",
        "    * นำไฟล์ csv - log_order.csv ไปใช้ในการส่งคำตอบ"
      ],
      "metadata": {
        "id": "zuds6aYnkvym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observers.save_csv()"
      ],
      "metadata": {
        "id": "mV1_25tbj4Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers = Observers(30,train=False)"
      ],
      "metadata": {
        "id": "z8WCPI6hcAgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observers.getWindowPrice()"
      ],
      "metadata": {
        "id": "uGY44SMycQ8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}